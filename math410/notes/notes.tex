\documentclass[12pt]{scrartcl}
\usepackage[sexy]{james}
\usepackage[noend]{algpseudocode}
\setlength{\marginparwidth}{2cm}
\usepackage{answers}
\usepackage{array}
\usepackage{tikz}
\newenvironment{allintypewriter}{\ttfamily}{\par}
\usepackage{listings}
\usepackage{xcolor}
\usetikzlibrary{arrows.meta}
\usepackage{color}
\usepackage{mathtools}
\newcommand{\U}{\mathcal{U}}
\newcommand{\E}{\mathbb{E}}
\usetikzlibrary{arrows}
\Newassociation{hint}{hintitem}{all-hints}
\renewcommand{\solutionextension}{out}
\renewenvironment{hintitem}[1]{\item[\bfseries #1.]}{}
\renewcommand{\O}{\mathcal{O}}
\declaretheorem[style=thmbluebox,name={Chinese Remainder Theorem}]{CRT}
\renewcommand{\theCRT}{\Alph{CRT}}
\setlength\parindent{0pt}
\usepackage{sansmath}
\usepackage{pgfplots}


\usetikzlibrary{automata}
\usetikzlibrary{positioning}  %                 ...positioning nodes
\usetikzlibrary{arrows}       %                 ...customizing arrows
\newcommand{\eqdef}{=\vcentcolon}
\newcommand{\tr}{{\rm tr\ }}
\newcommand{\im}{{\rm Im\ }}
\newcommand{\pw}{\overset{\text{p.w.}}{\longrightarrow}}
\newcommand{\spann}{{\rm span\ }}
\newcommand{\Col}{{\rm Col\ }}
\newcommand{\Row}{{\rm Row\ }}
\newcommand{\dint}{\displaystyle\int}
\newcommand{\dt}{\ {\rm d }t}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\lint}{\int_{\overset{a}{\_}}^{b}}
\newcommand{\uint}{\int_a^{\bar{b}}}
\newcommand{\horizontal}{\par\noindent\rule{\textwidth}{0.4pt}}
\newcommand{\Lim}{\underset{n\to\infty}{\lim}}
\usepackage[top=3cm,left=3cm,right=3cm,bottom=3cm]{geometry}
\newcommand{\mref}[3][red]{\hypersetup{linkcolor=#1}\cref{#2}{#3}\hypersetup{linkcolor=blue}}%<<<changed

\tikzset{node distance=4.5cm, % Minimum distance between two nodes. Change if necessary.
         every state/.style={ % Sets the properties for each state
           semithick,
           fill=cyan!40},
         initial text={},     % No label on start arrow
         double distance=4pt, % Adjust appearance of accept states
         every edge/.style={  % Sets the properties for each transition
         draw,
           ->,>=stealth',     % Makes edges directed with bold arrowheads
           auto,
           semithick}}


% Start of document.
\newcommand{\sep}{\hspace*{.5em}}

\pgfplotsset{compat=1.18}
\begin{document}
\title{MATH410: Advanced Calculus I}
\author{James Zhang\thanks{Email: \mailto{jzhang72@terpmail.umd.edu}}}
\date{\today}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\maketitle
    These are my notes for UMD's MATH410: Advanced Calculus I. 
    These notes are taken live in class (``live-\TeX``-ed).
    This course is taught by Lecturer Anna Szczekutowicz. 
\tableofcontents
\newpage

This section covers the foundation of analysis, which is just the set of real numbers. 
It covers basic definitions such as $\in, \notin, \emptyset, \subseteq, =, \cap, \cup, \backslash$, so for example

\begin{definition}
  \vocab{Intersection} of $A$ and $B$ is $C= A \cap B = \{x \ | \ x \in A \text{ and } x \in B\}$
\end{definition}

Some quantifiers include $\forall, \exists, \exists!$ and some number sets include $\RR, \NN, \ZZ, \QQ, \QQ^C$. 

\begin{definition}
  The real numbers \vocab{$\RR$} satisfies 3 groups of axioms: Refer to the notes on Canvas for the Consequences of all of the following axioms.
  \begin{enumerate}
    \item Field (+, $*$) 
    \begin{itemize}
      \item Commutativity of Addition
      \item Associativity
      \item Additive Identity
      \item Additive Inverse
      \item Commutativty of Multiplcation
      \item Associativity of Multiplication
      \item Multiplicative Identity
      \item Multiplicative Inverse
      \item Distributive Property
    \end{itemize}
  The set of integers $\ZZ$ is not a field because it fails under the multiplicative inverse.
    \item Positivity
    
    There is a subset of $\RR$ denoted by $\mathcal{P}$, called the set of positive numbers for which: 
    \begin{itemize}
      \item If $x$ and $y$ are positive, then $x + y$ and $xy$ are both positive.
      \item For each $x \in \RR$, eaxctly one of the following 3 alternatives is true: $x \in \mathcal{P}$, $-x \in \mathcal{P}$, or $x = 0$
    \end{itemize}

    \item Completeness
  \end{enumerate}
\end{definition}

\begin{definition}
  \vocab{Absolute value} is defined as 
  \[|x| = \begin{cases}
    x \text{ if } x \geq 0\\
    -x \text{ if } x < 0Â 
  \end{cases}\]

\end{definition}

\begin{definition}
  \vocab{Triangle Inequality} is $\forall \ a, b \in \RR, |a + b| \leq |a| + |b|$
\end{definition}

\begin{proof}
  Assume without loss of generality, $a \geq b$. We will proceed with proof by cases.

  Case 1: Assume $a \geq b \geq 0$. Then $|a + b| = a + b$ by the definition of absolute value since 
  $a \geq 0, b \geq 0 \implies |a + b| = a + b = |a| + |b|$.

  Case 2: Now assume $a \geq 0 \geq b$ and $a + b \geq 0$. Note since $b \leq 0$ then 
  $b \leq |b|$. Then 
  \[|a + b| = a + b \leq |a| + |b|\]
  by the definition of absolute value and our above note.

  Case 3: Now consider $a \geq 0 \geq b$ and $a + b < 0$. So 
  \[|a + b| = -(a + b) = -a - b \leq |a| + |b|\]

  Case 4: Now consider $0 \geq a \geq b$ so $a + b < 0$.
  Therefore, 
  \[|a + b| = -(a + b) = -a + - b = |a| + |b|\]

\end{proof}

\section{The Completeness Axiom}

\begin{definition}
  A subset S of $\RR$ is said to be \vocab{bounded above} if $\exists \ r\in\RR$ such that
  $s \leq r \ \forall \ s \in S$

  The definition of \vocab{bounded below} is similar.
\end{definition}

\begin{definition}
  The least upper bound, if it exists, is called the \vocab{supremum} of $S$. 
  We denote it as the "sup" of $S$. Similarly, the largest lower bound is called
  the \vocab{infemum} and is denoted as the "inf" of $S$.
\end{definition}

\begin{definition}
  Let $S \subseteq R$ where $S\ \neq \ \emptyset$. If $S$ has a largest (smallest), 
  the element is a max (min).
\end{definition}


\begin{example}
  Find the sup of $(0, 1)$ and prove it. 
  \begin{proof}

    Let us prove that the $sup(0, 1) = 1$. First, let us show that we have 
    an upperbound. If $x \in (0, 1)$, then $x \leq 1$. By definition of upperbound,
    1 is an upper bound. Note that we can find many other upper bounds. 
    
    On the contrary, assume $x < 1$ is an upper bound. Now consider the average
    $\frac{1 + x}{2}$. 
    \[\frac{x + 1}{2} < \frac{1 + 1}{2} = 1\]
    Therefore, we have showed that $0 < \frac{x + 1}{2} < 1 \implies \frac{x + 1}{2} (0, 1)$. 
    But, $\frac{1 + x}{2} > \frac{x + x}{2} \implies \frac{1 + x}{2} > x$. This is a contradiction. Since 
    $x$ is an upper bound, and we found $\frac{1 + x}{2} \in (0, 1)$ where $\frac{1 + x}{2} > x$, 
    so $x$ is not a supremum.

  \end{proof}
\end{example}

\begin{theorem}
  Suppose $S \in \RR, S \neq \emptyset$ that is bounded above. Then a 
  supremum exists. Every nonsempty subset $S$ of $\RR$ that is bounded below has a
  lower bound.
\end{theorem}

\begin{note}
  Let $c$ be a positive number then $\exists !$ a positive number whose
  square is $c$. $x^2 = c, x > 0$ has a unique solution and this gives us 
  the notion of square root. 
\end{note}

\subsection{Archimedian Property}

\begin{definition}
  The \vocab{Archimedian Property} is a result of the completeness axiom. Suppose there 
  is a small $\epsilon > 0$ and $c$ is an arbitrary large number. 
  \begin{enumerate}
    \item $\exists \ n \in \NN$ such that $c < n$, which just means that you can always find a 
  natural number than any large number
    \item $\exists \ m \in \NN$ such that $\frac{1}{m} < \epsilon$, which just means you can always
  find smaller rational numbers.
  \end{enumerate}
\end{definition}

\begin{proof}
  
  We will proceed by contradiction. Assume that $\exists$ an upper bound $c$ for the 
  $\NN$. So there is no $n \in \NN$ s.t. $c < n$. Since $\NN$ is bounded above, and 
  the $\NN$ is nonempty, the supremum exists (Completeness Axiom). 
  Let $s = \sup \NN$. Consider $s - 1$ and $s - 1 < s = \sup \NN$, which is the least
  upper bound, so $s - 1$ is not an upper bound. So $\exists n \in \NN$ such that $s - 1 < n \implies 
  s < n + 1$. But $s = \sup \NN$, the least upper bound, this is a contradiction since it 
  is less than $(n + 1) \in \NN$. 
  
  For part $b$, use $c = \frac{1}{\epsilon}$ and use part $a$. 
\end{proof}

\begin{note}
  Some of the following are results from the Archimedian Property. 

  \begin{theorem}
    For all $n \in \ZZ$, there is no integer in $(n, n + 1)$ (an open interval).
  \end{theorem}

  \begin{theorem}
    If $S$ is a nonempty subset of $\ZZ$ that is bounded above, then it has a max. 
  \end{theorem}

  \begin{theorem}
    $*$ For every $c \in \RR, \ \exists ! \ n \in \ZZ \text{ in } [c, c + 1)$
  \end{theorem}

\end{note}

\begin{definition}
  A subset $S \subseteq \RR$ is said to be \vocab{dense in $\RR$} if for every $a, b \in \RR$
  with $a < b$, then there is a $s \in S$ s.t. $s \in (a, b)$.
\end{definition}

\begin{theorem}
  $\QQ$ is dense in $\RR$. Reminder that $\QQ = \{\frac{m}{n} \ | \ m, n \in \ZZ, n \neq 0\}$

  \begin{proof}
    Suppose we have arbitrary $a, b \in \RR$ and $a < b$. We want to find $\frac{m}{n} \in (a, b)$. 
    By multiplcation, we can say we want $na < m < nb$. We want an integer $m$ between
    $na$ and $nb$. We can write this as 
    \[nb - na > 1 \implies n(b-a) > 1 \implies n > \frac{1}{b-a}\]
    By part $a$ of the Archimedian Property, let $c = \frac{1}{b-a}$, and we know that 
    there exists some $n \in \NN$ such that $n > c$. Since $a < b$, and $b - a > 0$, 
    multiply
    \[n > \frac{1}{b-a}\]
    \[n(b-a) > 1\]
    \[nb - na > 1\]
    \[nb - 1 > na \implies na < nb - 1\]
    By previous $(*), \ \exists \ m \in \ZZ$ s.t. $m \in [nb-1, nb)$. Therefore, 
    $nb - 1 \leq m < nb$. Therefore, 
    \[na < nb - 1 \leq m < nb \implies na < m < nb \implies a < \frac{m}{n} < b\]
    and so we have found that there exists $m \in \ZZ, n \in \NN$ such that $\frac{m}{n} \in (a, b)$ 
    for all $a, b \in \RR$ and $a < b$. Therefore, the rational numbers are dense in the real numbers. 
  \end{proof}
\end{theorem}

\section{Sequences}

\begin{definition}
  A \vocab{sequence} of $\RR$ is a real-valued function whose domain is $\NN$. 
  $f: \NN \rightarrow \RR$ (a list of numbers indiced by $\NN$)
\end{definition}

\begin{example}
  A sequence of odd integers could be $a_1 = 1, a_2 = 3, a_3 = 5, \ldots, a_n = 2n-1$
  which can be 
  \[\{1, 3, 5, \cdots\} = \{a_n \}_{n=1}^\infty = \{2n-1\}_{n=1}^\infty\]
\end{example}

\begin{example}
  \[\{\frac{1}{n}\} = \{\frac{1}{n}\}_{n=1}^\infty \implies \{1, \frac{1}{2}, \frac{1}{3}, \ldots\}\]
\end{example}

\subsection{Convergence}

\begin{definition}
  A sequence $\{a_n\}$ is said to \vocab{converge} to a number $L$ if 
  $\forall \epsilon > 0, \ \exists$ an index $N$ s.t. $\forall $ indices $n \geq N$
  we have 
  \[|a_n - L| < \epsilon \implies \text{Notation: } \lim_{n\to\infty}a_n = L\]
\end{definition}

\begin{example}
  Suppose we have the sequence $\{\frac{(-1)^n}{n}\}$ and we WTS 
  \[\lim_{n\to\infty}\frac{(-1)^n}{n} = 0\]

  Think of the problem as someone gives you a small $\epsilon \implies$ you have to find $N$, 
  which we call the \vocab{threshold}, such that for every sequence value after the threshold 
  is in the $\epsilon-$tube.

  For example, $\epsilon = \frac{1}{2} \implies N = 3, \epsilon = \frac{1}{4} \implies N = 5$.

  \hfill

  Above $L = 0$, sketch: we want 
  \[|a_n - L| < \epsilon \implies |\frac{(-1)^n}{n} - 0| < \epsilon \implies |\frac{1}{n}| < \epsilon \implies \frac{1}{\epsilon} < n\]
  so choose $N = \frac{1}{\epsilon} < n$

  \begin{proof}
    Let $\epsilon > 0$ be given. By Archimedian Property, $\exists N \in \NN$ such that 
    $\frac{1}{N} < \epsilon$. Then if $n \geq N$
    \[|\frac{(-1)^n}{n} - 0| = |\frac{(-1)^n}{n}| = |\frac{1}{n}| = \frac{1}{n}\]
    From here, we need to relate $n$ to $N$ and then we can relate $N$ to $\epsilon$. 
    Note that $n \geq N \implies \frac{1}{N} \geq \frac{1}{n}$ by algebra. Therefore, 
    \[\frac{1}{n} \leq \frac{1}{N} < \epsilon\]
    by our choice of $N$. Therefore, 
    \[\frac{1}{n} < \epsilon\] and 
    so we are done since we have shown that 
    \[|\frac{(-1)^n}{n} < 0| < \epsilon\]
  \end{proof}
\end{example}

\begin{example}
  Given $\{\frac{n^2 - 2n}{n^2 + 1}\}$, prove that this sequence $\underset{n\to\infty}{\lim}\frac{n^2 - 2n}{n^2 + 1} = 1$.

  Some sketch work: we want to show that $|\frac{n^2 - 2n}{n^2 + 1} - 1| < \epsilon$
  \[|\frac{n^2 - 2n}{n^2 + 1} - 1| = |\frac{n^2 - 2n}{n^2 + 1} - \frac{n^2 + 1}{n^2 + 1}| = |\frac{-2n - 1}{n^2 + 1}| = |\frac{2n + 1}{n^2 + 1}|\]
  Note that both the numerator and denominator are both always positive, so we can consider. 
  Now let us use the $\leq$ operator to simplify and have one singular `n`.
  \[\frac{2n+1}{n^2+1} \leq \frac{2n + 1}{n^2} \leq \frac{2n+n}{n^2} = \frac{3n}{n^2} = \frac{3}{n}\]
  Recall that $n \geq N \implies \frac{1}{N} \geq \frac{1}{n} \implies \frac{1}{n} \leq \frac{1}{N}$
  So we'd choose $N$ to get rid of $3$ and introduce $\epsilon$. 
  \begin{proof}
    Let $\epsilon > 0$. By A.P., $\exists \ N \in \NN$ s.t. $\frac{1}{N} < \frac{\epsilon}{3}$. 
    For $n \geq N$, then
    \[|\frac{n^2-2n}{n^2 + 1} - 1| = \cdots = \frac{2n + 1}{n^2 + 1} < \cdots \leq \frac{3}{n} \leq \frac{3}{N} = 3 * \frac{1}{N} < 3 * \frac{\epsilon}{3} = \epsilon\]
    Therefore, we have shown that
    \[|a_n - L| < \epsilon \ \implies \ \lim_{n\to\infty}\frac{n^2-2n}{n^2 + 1} = 1\]
  \end{proof}
\end{example}

\begin{theorem}
  \vocab{The Sum Property} states that if
  \[\lim_{n\to\infty} a_n = a \text{ and } \lim_{n\to\infty}b_n = b\]
  then 
  \[\lim_{n\to\infty}(a_n + b_n) = \lim_{n\to\infty}a_n + \lim_{n\to\infty}b_n = a + b\]

  Some sketch work before the proof:

  We want to show that $|a_n + b_n - (a + b)| < \epsilon$. Note that we can group terms together
  $|(a_n - a) + (b_n - b)| \leq |a_n - a| + |b_n - b|$ by the Triangle Inequality. 
  It is known that these two terms converge. Therefore, we can choose $\epsilon$s such that 
  \[|a_n - a| + |b_n - b| \leq \frac{\epsilon}{2} + \frac{\epsilon}{2}\]

  \begin{proof}
    
    \hfill

    Let $\epsilon > 0$. Since the sequences $\{a_n\}$ and $\{b_n\}$ converge to $a$ and $b$, 
    respectively, by the Archimedian Principle, $\exists N_1, N_2 \in \NN$ such that 
    $\frac{1}{N_1} < \frac{\epsilon}{2}$ and $\frac{1}{N_2} < \frac{\epsilon}{2}$. 
    Choose $N = \max(N_1, N_2)$, which represents the numerically larger threshold.

    For all $n \geq N$, we show 
    \[|a_n + b_n - (a + b)| = |(a_n - a) + (b_n - b)| \leq |a_n - a| + |b_n - b|\]
    \[< \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]
    Therefore, we have shown that $\underset{n\to\infty}{\lim} (a_n + b_n) = a + b$
  \end{proof}

\end{theorem}

\begin{lemma}
  \vocab{The Comparison Lemma (C.L.)}
  
  \hfill

  Let $\{a_n\}$ converge to $a$. Then $\{b_n\}$ converges to $b$ if $\ \exists \ c \in \RR^+$
  and $N \in \NN$ such that
  \[\forall \ n \geq N, \ |b_n - b| \leq c|a_n - a|\]
  \begin{proof}
    Let $\epsilon > 0$. Since $a_n$ converges to $a, \ \exists \ N_1 \in \NN$ such that 
    $|a_n - a| < \frac{\epsilon}{c}, \ \ \forall \ n \geq N_1$. By the Archimedian Principle,
    $\exists \ N_2 \in \NN$ such that $\frac{1}{N_2} < \epsilon$. Choose $N = \max(N_1, N_2)$
    and if $n \geq N$, then 
    \[|b_n - b| \leq c |a_n - a| < c * \frac{\epsilon}{c} = \epsilon\]
    \[\implies |b_n - b| < \epsilon\]
  \end{proof}
\end{lemma}

\begin{lemma}
  Suppose the $\underset{n\to\infty}{\lim} a_n = a$, then for $c \in \RR$, 
  \[\lim_{n\to\infty}ca_n = c\lim_{n\to\infty}a_n = ca\]

  \begin{proof}
    Use the Comparison Lemma (above). Note that $|ca_n - ca| = |c(a_n-a)| = |c||a_n - a|$ 
    which satisfies $|b_n - b| \leq c|a_n - a| \implies \{b_n\} = \{ca_n\} \implies b = ca$.
  \end{proof}
\end{lemma}

\begin{lemma}
  The following is a useful property (*)
  \[\lim_{n\to\infty}a_n = a \underset{\leftrightarrow}{\text{ iff }} \lim_{n\to\infty}(a_n - a) = 0\]

\end{lemma}

\begin{lemma}
  Suppose $\underset{n\to\infty}{\lim} a_n =0$ and $\underset{n\to\infty}{\lim}b_n = 0$ 
  then $\underset{n\to\infty}{\lim}a_n b_n = 0$.
  \begin{proof}
    Since $\underset{n\to\infty}{\lim} a_n = 0$ and $\sqrt{\epsilon} > 0$ ,
    \[\exists \ N_1 \in \NN \text{ s.t. } |a_n| < \sqrt{\epsilon} \ \forall \ n \geq N_1\]
    Since $\underset{n\to\infty}{\lim}b_n = 0$ and $\sqrt{\epsilon} > 0$, 
    \[\exists \ N_1 \in \NN \text{ s.t. } |b_n| < \sqrt{\epsilon} \ \forall \ n \geq N_2\]
    Let $N = \max(N_1, N_2)$. Then if $n\geq N$,
    \[|a_nb_n - 0| = |a_n b_n| = |a_n| * |b_n| < \sqrt{\epsilon} * \sqrt{\epsilon} = \epsilon\]
  \end{proof}
\end{lemma}

\begin{theorem}
  \vocab{The Product Property} states that if $\underset{n\to\infty}{\lim}a_n = a$ and $\underset{n\to\infty}{\lim}b_n = b$ then 
  $\underset{n\to\infty}{\lim}a_n b_n = ab$
  \begin{proof}
    Define $\alpha_n = a_n - a$ and $\beta_n = b_n - b$. Using the * property above, 
    since $\underset{n\to\infty}{\lim}a_n = a \implies \underset{n\to\infty}{\lim} (a_n - a) = \underset{n\to\infty}{\lim}\alpha_n = 0$
    and then the same for $b$ such that $\underset{n\to\infty}{\lim}\beta_n = 0$.
    
    Note that 
    \[a_nb_n - ab = (\alpha_n + a)(\beta_n + b) - ab\] and then by Distributive property we get
    \[= \alpha_n\beta_n + \alpha_n b + a\beta_n + ab - ab = \alpha_n\beta_n + \alpha_n b + a\beta_n\]
    So using the previous lemma, 
    \[\lim_{n\to\infty}(a_n b_n - ab) = \lim_{n\to\infty}(\alpha_n \beta_n + b\alpha_n + a\beta_n) = \lim_{n\to\infty}(\alpha_n\beta_n) + b\lim_{n\to\infty}\alpha_n + a\lim_{n\to\infty}\beta_n\]
    From above, the last two terms are 0 and by the previous lemma, the first term is 0. 
    Therefore, 
    \[\lim_{n\to\infty}(a_nb_n - ab) \underset{\leftrightarrow}{\text{ iff }} \lim_{n\to\infty}(a_n b_n) = ab\]
  \end{proof}
\end{theorem}

\begin{definition}
  A sequence \vocab{diverges} to $\infty, (-\infty)$ if 
  \[\forall \ M > (<) 0, \exists \ N \in \NN \text{ s.t. } \forall n \in \NN, n \geq N \text{ then } a_n > (<) M\]
\end{definition}

\begin{example}
  Prove that $\underset{n\to\infty}{\lim}(n^2 - 4n) = \infty$

  Sketch: we want $a_n > M \implies n^2 - 4n > M \implies n(n-4) > M$
  
\begin{proof}

  Let $M > 0$ be given. By A.P., $\exists \ N \in \NN$ s.t. $N > \max(M, 4)$.
  If $n \geq N$, then $n^2 - 4n = n(n-4) \geq N(N - 4) > M$

  Thus, 
  \[n^2 - 4n \to \infty \text{ as } n \to \infty\]
\end{proof}

\end{example}

\begin{example}
  Prove that $(-1)^n$ does not converge. 

  \begin{proof}
    On the contrary, suppose $(-1)^n$ converges to $a$. Let $\epsilon = 1$. In the definition of 
    convergence, then $\exists \ N \in \NN$ if $n \geq N$ then 
    \[|(-1)^n - a| < 1\]
    For $n = 2N$, meaning some even number, we get $|(-1)^n - a| = |1 - a| < 1$

    Now for $n = 2N + 1$, we get $|(-1)^{2N+ 1} -a| = |1 + a| < 1$

    Note that $|1 - a| < 1$ and $|1 + a| < 1$ so therefore
    \[|1 - a| + |1 + a| < 2\]
    But note, using the Triangle Inequality in the reverse direction, 
    note that $2 = |1 - a + 1 + a| \leq |1 - a| + |1 + a| < 1 + 1 = 2$. Therefore, we've shown 
    that $2 < 2$ which is a contradiction and therefore, $(-1)^n$ does not converge. 
  \end{proof}
\end{example}

\begin{lemma}
  Suppose the sequence $\{b_n\}$ of nonzero numbers converges to $b \neq 0$. Then 
  $\{\frac{1}{b_n}\}$ converges to $\frac{1}{b}$.
    
    Sketch: Use the Comparison Lemma to find $c \in\RR^+$ and $N_1 \in \NN$ such that 
    \[|\frac{1}{b_n} - \frac{1}{b}| < c|b_n - b|\]
    We just have to find $c$ and $N_1$. 

  \begin{proof}
    Note that 
    \[|\frac{1}{b_n} - \frac{1}{b}| = |\frac{b - b_n}{bb_n}| = \frac{1}{|b||b_n|}|b_n - b|\]

    We want $\frac{1}{|b||b_n|}$ to be $c$, but this must be a single constant and not dependent on $n$. 
    We want to find index $N_1$ such that \[|b_n| > \frac{|b|}{2} \ \forall \ n \geq N_1\]
    \[\frac{1}{|b_n|} < \frac{2}{|b|}\]
    If we can find $N_1$ then $|\frac{1}{b_n} - \frac{1}{b}| \leq \frac{2}{|b|^2}|b_n - b|$ and the term
    $\frac{2}{|b|^2}$ becomes our $c$ and we can apply the Comparison Lemma, so we need $N_1$ to make the 
    above true.

    Let $\epsilon = \frac{b}{2}$. By definition of $\{b_n\}$ converging to $b$, we can choose $N_1$
    such that $|b_n - b| < \epsilon \ \forall \ n \geq N_1$.
    \[|b_n - b| < \frac{|b|}{2}\]
    \[-\epsilon < b_n - b < \epsilon\]
    \[b - \epsilon < b_n < b + \epsilon\]
    Check $b > 0, b < 0$ since $\epsilon = \frac{|b|}{2}$. When $b> 0, \epsilon = \frac{b}{2}$ so 
    \[b_n \in (b- \frac{b}{2}, b + \frac{b}{2}) = (\frac{b}{2}, \frac{3b}{2}  )\]
    so $b_n > \frac{b}{2}$. When $b < 0$ \dots
    So $|b_n| > \frac{|b|}{2}$ and this $N_1$ works and apply the Comparison Lemma.
  \end{proof}
\end{lemma}

\begin{theorem}
  Let $\underset{n\to\infty}{\lim}a_n = a, \underset{n\to\infty}{\lim}b_n = b$, and $b_n \neq 0 \forall \ n$ and 
  $b \neq 0$ then 
  \[\underset{n\to\infty}{\frac{a_n}{b_n}} = \frac{a}{b}\]
  \begin{proof}
    \[\lim_{n\to\infty}\frac{a_n}{b_n} = \lim_{n\to\infty}a_n * \frac{1}{b_n} = \lim_{n\to\infty}a_n * \lim_{n\to\infty}\frac{1}{b_n} = \frac{a}{b}\]
  \end{proof}
\end{theorem}

\subsection{Boundedness}

\begin{definition}
  A sequence $\{a_n\}$ is \vocab{bounded} if $\ \exists \ M \in \RR$ such that $|a_n| \leq M \ \forall \ n$.  
\end{definition}

\begin{theorem}
  Every convergent sequence is bounded. 
  \begin{itemize}
    \item If convergent $\implies$ bounded.
    \item If it is unbounded, then it diverges. 
  \end{itemize}
  
  \begin{proof}
      Let $\underset{n\to\infty}{\lim}a_n = a$ and take $\epsilon = 1$. Using the definition of 
      convergence, $\ \exists \ N \in \NN$ s.t. 
      \[|a_n - a| > 1 \ \forall \ n \geq N\]
      then $|a_n| = |a_n - a + a| \leq |a_n - a| + |a| \leq 1 + |a| \ \forall \ n \geq N$ by the 
      Triangle Inequality and then the definition of the converging sequence. However, we need
      to show that this is true (bounded by a constant) for all $n$, not just for all $n \geq N$. 

      \hfill

      Define $M = \max(1 + |a|, |a_1|, \ldots, |a_{N-1}|)$. Note that there the $N-1$ terms are finite 
      and so a $\max$ exists. Then 
      \[|a_n| \leq M \ \forall \ n\]
      and so $\{a_n\}$ is bounded.
  \end{proof}
\end{theorem}

\begin{remark}
  Recall that a set $S \subset \RR$ is dense in $\RR$ if every open set $(a, b) \in \RR$ contains a 
  point $s \in S$.
\end{remark}

\begin{definition}
  A set of numbers $\{x_n\}$ is in a set $S$ provided that $x_n \in S \ \forall \ n$.
\end{definition}

\begin{lemma}
  A set $S$ is \vocab{dense} in $\RR$ if and only if every $x \in \RR$ is a limit of a sequence of a 
  sequence in $S$. 
  
  \begin{proof}
    
    \hfill

    $\Longrightarrow$ Let $S \subset \RR$ be dense in $\RR$. Fix $x \in \RR$ and let $n$ be an index. 
    Since $S$ is dense, there is an element in $S$ in $(x, x + \frac{1}{n})$. For each $n$, this 
    defines $\{s_n\}$ with 
    \[s \in (x, x + \frac{1}{n})\]
    \[x < s < x + \frac{1}{n}\]
    \[|s_n - x| < \frac{1}{n} \ \forall \ n\]
    \[|s_n - x| < 1|\frac{1}{n} - 0|\]
    Use the Comparison Lemma since $\{\frac{1}{n}\}$ converges to $0$. So, $\{s_n\}$ converges to $x$. 
    
    \hfill

    $\Longleftarrow$ Let $S$ have the property that every number in $\RR$ is the limit of a sequence in 
    $S$. We want to show that any open interval in $\RR$ contains a point $s \in S$. 
    Consider an open interval $(a, b) \in \RR$. Consider $\frac{a + b}{2} = s \in \RR$. 
    By assumption, $\ \exists \{s_n\}$ of points in $S$ s.t. $\underset{n\to\infty}{\lim}s_n = s$.
    Define $\epsilon = \frac{b - a}{2} > 0$. 
    By definition of convergence, $\ \exists \ N$ s.t. $|s_n - s| < \epsilon \ \forall \ n \in \NN$. 
    \[-\epsilon < s_n - s < \epsilon\]
    \[s - \epsilon < s_n < s + \epsilon\]
    \[\frac{a+b}{2} - \frac{b-a}{2} < s_n < \frac{a+b}{2} + \frac{b-a}{2}\]
    \[a < s_n < b\]
    The point $s_N \in S$ and $s_n \in (a, b)$ so $S$ is dense in $\RR$. 

  \end{proof}
\end{lemma}

\begin{definition}
  The \vocab{sequential density of $\QQ$} states that every $\RR$ is the likmit of a sequence in 
  $\QQ$. 
\end{definition}

\begin{theorem}
  Let $\{c_n\} \in [a, b]$ and $\underset{n\to\infty}{\lim}c_n = c$ then $c \in [a, b]$ also. 
\end{theorem}

\begin{definition}
  $S \subset \RR$ is said to be \vocab{closed} (set) if $\{a_n\}$ is a sequence in $S$ that converges to $a$, 
  then $a \in S$ also.
\end{definition}

\begin{example}
  $(0, 1]$ not closed since $\{\frac{1}{n} \in (0, 1]\}$ and $\underset{n\to\infty}{\lim}\frac{1}{n} = 0$ but $0 \notin (0, 1]$. 
\end{example}

\begin{example}
  $\QQ$ is not closed since we can find $\{r_n\} \in \QQ$ that converge to $\pi$ but $\pi \notin \QQ$.  
\end{example}

\begin{definition}
  A $\{a_n\}$ is said to be \vocab{monotonically increasing (decreasing)} if $a_{n+1} \geq (\leq) a_n \ \forall \ n$
\end{definition}

\begin{note}
  If a sequence is monotone, then it is either monotonically increasing or decreasing.
\end{note}

\begin{theorem}
  \vocab{Monotone Convergence Theorem (MCT)} states that a monotone sequence converges if and only if 
  it is bounded. Moreover, the bounded monotone $\{a_n\}$ converges to the 
  \begin{enumerate}
    \item $\sup\{a_n \ | \ n \in \NN\}$ if monotone increasing
    \item $\inf\{a_n \ | \ n \in \NN\}$ if monotone decreasing
  \end{enumerate}

  \begin{proof}
    
    \hfill

    $\Longrightarrow$ Note that we already showed that convergent sequences are bounded. 

    \hfill

    $\Longleftarrow$ We want to show that our sequence 
    converges to either the $\inf, \sup$ depending on if its either increasing or decreasing.
    Now assume that our sequence is bounded. Define $S = \{a_n \ | \ n \in \NN\}$ and $S$ is bounded
    by assumption. Since $S$ is nonempty and bounded above, $S$ has $\sup S = l$ by the Completeness Axiom.
    Claim $\underset{n\to\infty}{\lim}a_n = l$. Let $\epsilon > 0$ be given, and we want to show the usual definition 
    of convergence. 

    Note that 
    \[|a_n - l| < \epsilon\]
    \[-\epsilon < a_n - l  < \epsilon\]
    \[l - \epsilon< a_n < l + \epsilon \ \forall \ n \geq N\]
    But $l$ is an upper bound for $S \implies a_n \leq l < l + \epsilon \ \forall \ n$. 
    
    On the other hand, since $l$ is the least upper bound for $S$, $l - \epsilon$ is not an upper bound for $S$. 
    So, $\ \exists \ N$ such that $l - \epsilon < a_N$. 

    Since $a_n$ is monotonically increasing. $l - \epsilon < a_N \leq a_n \ \forall n \geq N$. Thus, we have 
    $N \in \NN$ such that $\forall n \geq N$ we have $|a_n - l| < \epsilon$, as desired.
  \end{proof}
\end{theorem}

\begin{remark}
  The formula for a finite geometric sum is
  $S_n = \sum_{k=1}^n r^k$ where $r \neq 1, r < 1$.
  \[S_n = \frac{r - r^{n+1}}{1 - r}\] 

  \begin{example}
    Consider $S_n = \sum_{k=1}^n \frac{1}{k} \cdot \frac{1}{2^k}$
    \[k = 1 \implies s_1 = \frac{1}{2}\] 
    \[k = 2 \implies s_2 = \frac{1}{2} + \frac{1}{2} \cdot \frac{1}{2^2} = \frac{5}{8}\]
    \[k = 3 \implies \frac{1}{2} + \frac{1}{8} + \frac{1}{3} \cdot \frac{1}{2^3}\]
    \[\vdots\]
    so this sequence is monotonically increasing. Is it bounded 
    \[S_n = \sum_{k=1}^{n}\frac{1}{k} \cdot \frac{1}{2^k} \leq \sum_{k=1}^n \frac{1}{2^k} = \frac{\frac{1}{2} - \frac{1}{2}^{n+1}}{1 - \frac{1}{2}} = 1\]
  \end{example}
\end{remark}

\begin{theorem}
  \vocab{The Nested Interval Theorem}. Suppose that $I_n = [a_n, b_n]$ is a sequence of intervals, 
  for which $I_{n+1} \subset I_n \ \forall \ n$. Then the intersection of those intervals 
  is a nonempty closed interval 
  \[\cap_{i=1}^\infty I_n = [a, b]\] 
  where $a = \sup a_n, b = \inf b_n$. 
  Furthermore, if $\underset{n\to\infty}{\lim}a_n - b_n = 0$ then 
  $\cap_{i=1}^\infty I_n$ contains a single point. 
  \begin{proof}
    
    \hfill

    $\Longleftarrow$ Let $X \in \cap_{i=1}^\infty I_n$. So for all $n \in \NN, x \in I_n$
    by definition of intersection. Therefore, 
    \[a_n \leq x \leq b_n \ \forall \ n\]
    Note that $xx$ is an upper bound for $a_n$. So, by definition of $\sup$, $a = \sup a_n \leq x$. 
    \[a \leq x \leq b \implies x \in [a, b]\]

    \hfill

    $\Longrightarrow$ The reverse direction is similar. 
  \end{proof}
\end{theorem}

\subsection{Sequential Compactness}

\begin{definition}
  Consider a sequence $\{a_n\}$ and let $\{n_k\}$ be a sequence of $\NN$ that is strictly increasing.
  Then the sequence $\{b_k\}$ defined by $b_k = a_{n_k} \ \forall \ k$
  is a \vocab{subsequence}.
\end{definition}

\begin{note}
  Note that a sequence may not converge, but it may be possible to find a subsequence that does.
\end{note}

\begin{theorem}
  Let $\{a_n\}$ converges to $a$. Then every subsequence of $\{a_n\}$ also converges to the same limit $a$. 
\end{theorem}

\begin{theorem}
  Every sequence (does not need to converge) has a monotone increasing or decreasing subsequence.
  \begin{proof}
    Consider $\{a_n\}$. We all an index a \vocab{peak index} for $\{a_n\}$ if 
    \[a_n \leq a_m \ \forall \ n \geq m\]
    You can have two cases: infinitely many peak indices, or a finite number of peak indices.

    Suppose there are finite number of peak indices. Then we choose $N$ such that there are no 
    more peak indices. Since $N$ is not a peak index, $\exists \ n_1 \in \NN$ such that 
    $n_1 > N$ with $a_N \leq a_{n_1}$
    \[\vdots\]
    Continue for $n_k \implies \exists \ n_{k+1} \in \NN$ with $n_{k+1} \geq n_k$ with $a_{n_k} \leq a_{n_{k+1}}$
    \[a_N \leq a_{n_1} \leq \cdots \leq a_{n_k} \leq a_{n_{k+1}}\]
    which is a monotonically increasing subsequence. 

    In the case of infinitely many peak indices, $m_1 < m_2 < m_3 < \cdots < $ peak indices. 
    Since $m_1$ is a peak index. Then $m_1 < m_2 \implies a_{m_1} > a_{m_2}$.
    \[\vdots\]
    We'll get a monotonically decreasing subsequence.
  \end{proof}
\end{theorem}

\begin{theorem}
  Every bounded sequence has a convergent subsequence.

  \begin{proof}
    Let $\{a_n\}$ be bounded. By the previous theorem, $\{a_n\}$ has a monotone subsequence. 
    Since $\{a_n\}$ is boundeed, $\{a_{n_k}\}$ is bounded also. By MCT, 
    $\{a_{n_k}\}$ converges since it is monotone and bounded.
  \end{proof}
\end{theorem}

\begin{definition}
  A $S \subset \RR$ is said to be \vocab{compact (or sequentially compact)} if every sequence 
  in $S$ has a convergent subsequence converging to a point in $S$. For a set to not be compact, 
  we find a sequence in $S$ that has no convergence subsequence that converges to a point in $S$. 
\end{definition}

\begin{example}
  $[1, \infty)$ is not compact. Consider $a_n = n, a_n \to\infty$ by Archimedian Principle. 
  Then every subsequence of $n_k$ also diverges to $\infty$. Thus, $\{a_n\}$ has no subsequence 
  that converges. 
\end{example}

\begin{example}
  $(0, 1]$ is not compact. Let $a_n = \frac{1}{n}, a_n\to 0, n\to\infty$, so every subsequence 
  converges to 0 also. But $0 \notin (0, 1]$ so it is not compact. 
\end{example}

\begin{theorem}
  \vocab{The Sequentially Compactness Theorem (SCT)} states that every interval $[a, b]$ such
  that $a, b \in \RR$ is sequentially compact. 

  \begin{proof}
    Let $\{a_n\}$ be in $[a, b]$. So, $a \leq a_n \leq b \ \forall \ n$. By a previous theorem, 
    since $\{a_n\}$ is bounded, there exists a convergent subsequence $\{a_{n_k}\}$. Assume 
    $\{a_{n_k}\} \to l$. Since $a \leq a_n \leq b \ \forall \ n$, then 
    \[a \leq a_{n_k} \leq b \ \forall \ n\]
    so $l \in [a, b]$ as desired. Therefore, $\{a_n\}$ has a convergent subsequence whose limit 
    is in the interval $[a, b]$, so it is sequentially compact.
  \end{proof}
\end{theorem}

\begin{theorem}
  Bolzano Weirstrass Theorem: If $S \subset \RR$, the following are equivalent 
  \[S \text{ is closed and bounded } \Longleftrightarrow S \text{ is compact }\]
\end{theorem}

\section{Continuous Functions}

\subsection{Continuity Basics}

\begin{note}
  Before $f: \NN \to \RR$ but now $f: D \subset \RR \to \RR$. $f(x)$ is the value the function
  assigns to $x$. 
\end{note}

\begin{definition}
  A function $f: D \to\RR$ is said to be \vocab{continuous at a point $x_0$} if whenerver 
  $\{x_n\}_{n=1}^\infty$ converges to $x_0 \in D$, the image sequence $\{f(x_n)\}_{n=1}^\infty$ 
  converges to $f(x_0)$.
\end{definition}

\begin{definition}
  A function $f: D \to \RR$ is \vocab{continuous} if $f$ is continuous at every point 
  in $D$.
\end{definition}

\begin{example}
  Consider $f(x) = x^2 + 7x - 3$. We want to show $f$ is continuous. Select 
  $x_0 \in \RR$ and let $\{x_n\} \to x_0 \implies \underset{n\to\infty}{\lim}x_n = x_0$.
  We want to show that 
  \[\lim_{n\to\infty}f(x_n) = f(x_0)\] 
  Note that 
  \[\underset{n\to\infty}{\lim}f(x_n) = \underset{n\to\infty}{\lim}x_n^2 + 7x_n -3\]
  by definition of $f$. 
  \[ = \lim_{n\to\infty}x_n^2 + 7\lim_{n\to\infty}x_n + \lim_{n\to\infty}3\]
  by properties of sequences. 
  \[= x_0^2 + 7x_0 - 3 = f(x_0)\]
  by the definition of $f$
\end{example}

\begin{remark}
  Given $f: D \to \RR, g: D \to \RR$ are continuous, then \[f \pm g, fg, \frac{f}{g} (g \neq 0)\] are continuous
  and this follows directly from convergent sequence properties from the previous chapter.
  Thus, polynomials are continuous. 

\end{remark}

\begin{example}
  Consider Dirichlet's function $f: \RR \to \RR$ such that 
  \[f(x) = \begin{cases}
    1 \text{ if x is rational }\\
    0 \text{ if x is irrational }
  \end{cases}\]

  Note that $f$ is defined on $\RR$ but it is discontinuous at $x_0 \in \RR$.

  \begin{proof}
    Let $x_0 \in \RR$. By sequential density of the $\QQ$ and $\QQ^c$, we can find 
    \[\{u_n\} \to x_0, u_n \in \QQ \ \forall n\]
    \[\{v_n\} \to x_0 , v_n \in \QQ^c \ \forall \ n\]
    Since $f(u_n) = 1 \ \forall \ n$ and $f(v_n) = 0 \ \forall \ n$, then 
    \[\{f(u_n)\} \to 1 \text{ but } \{f(v_n)\} \to 0\]
    Therefore, $\underset{n\to\infty}{\lim}f(u_n) = 1 \neq 0 = \underset{n\to\infty}{\lim}f(v_n)$
    but $\{u_n\} \to x_0$ and $\{v_n\} \to x_0$ but we cannot have 2 function values for $x_0$.
  \end{proof}
\end{example}

\begin{definition}
  Suppose $f: D \to \RR$ and $g: U \to \RR$ such that $f(D) \subset U$ then we define 
  \[(g \circ f)(x) = g(f(x)) \ \forall \ x\]
\end{definition}

\begin{theorem}
  Let $f: D \to \RR, g : U \to\RR$  and $f(D) \subset U$. Let $f$ be continuous at $x_0$ and $g$ be continuous at $f(x_0)$. 
  Then $(g \circ f): D \to \RR$ is continuous at $x_0$. 

  \begin{proof}
    Suppose $\{x_0\} \in D$ converges to $x_0$. Since $f$ is continuous, 
    
    then $\underset{n\to\infty}{\lim}f(x_n) = f(x_0)$. 
    \[\{f(x_n)\} \underset{n\to\infty}{\to}f(x_0)\]

    Since $g$ is continuous at $f(x_0)$, then $\underset{n\to\infty}{\lim}g(f(x_n)) = g(f(x_0))$.
    Therefore, $(g \circ f)(x)$ is continuous at $x_0$ since 
    \[\{g(f(x_n))\} \underset{n\to\infty}{\to} g(f(x_0))\]
    $\Longrightarrow$ we can combine continuous functions and remain continuous
  \end{proof}
\end{theorem}

\subsection{Extreme Value Theorem}

\begin{definition}
  $f: D \to \RR$ attains a \vocab{maximum (minimum)} value if there is
  \[x_0 \in D \text{ s.t. } f(x_0) \geq (\leq) f(x) \ \forall x \in D\]
\end{definition}

\begin{remark}
  Recall that a nonempty set has a maximum if it is bounded above and contains its supremum ie. the supremum is in the set.

  \hfill

  $\Longrightarrow$ Now $f: D \to \RR$ has a maximum when the image $f(D)$ is bounded above and 
  the supremum of the image is a functional value. 
\end{remark}

\begin{example}
  $f: (0, 1) \to \RR$ where $f(x) = 2x$. Note that the supremum of the image is 2, but 2 is not a functional value.
  Therefore, this function does not have a max.
\end{example}

\begin{theorem}
  The \vocab{Extreme Value Theorem} states that a continuous function on a closed and bounded interval $f: [a, b] \to \RR$ attains
  both a maximum and a minimum. 

  Sketch: Note that we want to show that $f(D)$ is bounded above. See lemma below. 
  After that, we need to show that the supremum is a functional value.

  \begin{lemma}
    Assume on the contrary that given $f: [a, b] \to \RR$ is continuous, assume there is no
    $M$ such that 
    \[f(x) \leq M \ \forall \ x \in [a, b]\]
    There is $x \in [a, b]$ at which $f(x) > n, \ \forall \ n$. For each $n$ this creates 
    a sequence $\{x_n\}$ in $[a, b]$ with $f(x) > n \ \forall \ n$.  $\{x_n\}$ may or may not converge. 
    By Sequential Compactness Theorem, choose $\{x_{n_k}\}$ subsequence that converges to $x_0 \in [a, b]$.
    Since $f$ is continuous at $x_0, \{f(x_{n_k})\} \to f(x_0)$, but every convergent sequence 
    is bounded by a theorem, so $\{f(x_{n_k})\}$ is bounded. Therefore, we have a contradiction 
    since $f(x_{n_k}) > n_k \geq k \ \forall k \ \in \NN$. So $f: [a, b] \to \RR$ is bounded above.
  \end{lemma}

  \begin{proof}
    Define $S = f([a, b])$, all of the image values. By the lemma above, $S$ is bounded. Note 
    $S$ is nonempty and bounded, thus by the Completeness Axiom, $c := \sup(S)$ exists.
    Note that we want to find $x_0 \in [a, b]$ such that $f(x_0) = c$, as this would show that 
    the supremum is a functional value. Consider 
    \[c - \frac{1}{n} < c \ \forall \ n\]
    Note that $c - \frac{1}{n}$ is not an upper bound since $c$ is the least upper bound. So, 
    we can find a point $x \in [a, b]$ such that 
    \[c - \frac{1}{n} < f(x) < c\]
    Label point $x_n$ to create a sequence $\{x_n\}$ 
    \[c - \frac{1}{n} < f(x_n) < c \ \forall \ n\] 
    Since $\{\frac{1}{n}\} \to 0$ as $n \to \infty$, then $\{f(x_n)\} \to c$ by the Squeeze Theorem, as desired.
    Note by the Sequential Compactness Theorem, there exists a subsequence $\{x_{n_k}\}$ that converges to 
    $x_0$. Since $f$ is continuous at $x_0$, then $\{f(x_{n_k})\} \to f(x_0)$. Recall that 
    $\{f(x_{n_k})\}$ is a subsequence of $\{f(x_n)\}$ that converges to $c$, and any subsequence must 
    also converge to the same value as the full sequence. Therefore, $f(x_0) = c$. 
    Therefore, the supremum exists and is a functional value, so we attain a max at $x_0$. 
  \end{proof}

\end{theorem}

\subsection{Intermediate Value Theorem}

\begin{theorem}
  \vocab{The Intermediate Value Theorem} state that suppose $f: [a, b] \to \RR$ is continuous, 
  let $c \in \RR$ between $f(a)$ and $f(b)$.
  Then there exists $x_0 \in (a, b)$ such that $f(x_0) = c$. 

  \begin{proof}
    Without loss of generality, suppose $f(a) < c < f(b)$. Recursively define a sequence of 
    nested intervals starting at $[a, b]$ and converging to $x_0 \in (a, b)$ with $f(x) = c$.
    We WTS $f(x_0) = c$ by letting $a_1 = a, b_1 = b \ \forall \ n$. 

    
    $\forall \ n$ define $[a_n, b_n]$ by considering the midpoint $m_n = \frac{a_n + b_n}{2}$. 
    Let us consider some cases. 

    $\Longrightarrow$ If $f(m_n) \leq c$, define $a_{n+1} = m_n$ and $b_{n+1} = b_n$. 

    $\Longleftarrow$ If $f(m_n) > c$, define $a_{n+1} = a_n$ and $b_{n+1} = m_n$. 

    Note that $a \leq a_n \leq a_{n+1} < b_{n+1} < b_n \leq b$ and $f(a_{n+1}) \leq c$ and $f(b_{n+1}) > c$ 
    by definition. Now, we want to show that 
    \[\lim_{n\to\infty}(b_n - a_n) = 0\]
    in order to apply the Nested Interval Theorem.
    \[\vdots\]
    So $b_n - a_n = \frac{b - a}{2^{n-1}} \ \forall \ n \underset{n\to\infty}{\to}0$. So 
    $\underset{n\to\infty}{\lim}(b_n - a_n) = 0$. Thus by Nested Interval Theorem, 
    $\ \exists \ x_0 \in (a, b)$ where $\{a_n\} \to x_0$ and $\{b_n\} \to x_0$. Since 
    $f$ is continuous at $x_0$, then $\{f(a_n)\} \to f(x_0)$ and $\{f(b_n) \to f(x_0)\}$. 
    Since $f(a_n) \leq c \ \forall \ n \implies f(x_0) \leq c$ and $f(b_n) \geq c \ \forall \ n \implies f(x_0) \geq c$.
    Thus, the only this is true is $f(x_0) = c$, as desired.
  \end{proof}
\end{theorem}

\begin{example}
  Suppose we have $h(x) = x^5 + x + 1 = 0$. $h(x)$ is a polynomial so it is continuous. 
  Verify that a solution exists. Let us test some points.
  \[h(0) = 0 + 0 + 1 = 1\]
  \[h(1) = 1 + 1 + 1 = 3\]
  \[h(-1) = -1 - 1 + 1 = -1\]
  By the Intermediate Value Theorem, there exists $x_0 \in (-1, 0)$ such that $x_0^5 + x_0 + 1 = 0$.
\end{example}

\begin{example}
  $x^2 = c, c > 0$. Verify that a solution exists. 
  \begin{proof}
    Consider $f: [0, c + 1] \to \RR$. $f(x) = x^2, 0 \leq x \leq c+ 1$. Testing points
    \[f(0) = 0^2 = 0 < c\]
    \[f(c + 1) = c^2 + 2c + 1 > c\]
    Since $x^2$ it is continuous. By IVT, there exists $x_0 \in (0, c + 1)$ such that $x_0^2 = c$.
  \end{proof}
\end{example}

\subsection{Uniform Continuity}

\begin{definition}
  A function $f: D \to \RR$ is said to be \vocab{uniformly continuous} if for $\{u_n\}$ and 
  $\{v_n\}$ in $D$ with $\underset{n\to\infty}{\lim}u_n - v_n = 0$ then $\underset{n\to\infty}{\lim}f(u_n) - f(v_n) = 0$. 
\end{definition}

\begin{note}
  It doesn't make sense to say $f$ is uniformly continuous at a singular point. Further note that 
  there is no requirement for $\{u_n\}$ and $\{v_n\}$ to converge. 
\end{note}

\begin{remark}
  Uniform continuity is on an interval. 
\end{remark}

\begin{example}
  $f: \RR \to \RR, f(x) = 3x$ is uniformly continuous. 

  \begin{proof}
    Let $\{u_n\}$ and $\{v_n\}$ be in $\RR$ and $\{u_n - v_n\} \to 0$. Then 
    \[\{f(u_n) - f(v_n)\} = \{3u_n - 3v_n\} = \{3(u_n - v_n)\} \to 3 * 0\]
    as needed.
  \end{proof}
\end{example}

\begin{example}
  $f(x) = x^2$ is not uniformly continuous on $f: \RR \to \RR$. To do this, we must 
  find a pair of sequences that doesn't work.

  \begin{proof}
    Let $\{u_n\} = \{n + \frac{1}{n}\}$ and $\{v_n\} = \{n\}$. Note that 
    $\{u_n - v_n\} \to 0$ but 
    \[\{f(u_n) - f(v_n)\} = \{f(n + \frac{1}{n}) - f(n)\} = \{(n + \frac{1}{n})^2 - n^2\} = \{2 + \frac{1}{n^2}\} \to 2 \neq 0\]    
    Therefore, $f$ is not uniformly continuous on $\RR$.
  \end{proof}
\end{example}

\begin{example}
  Consider $f: (0, 2) \to \RR$ and $f(x) = \frac{1}{x}$. This is not uniformly continuous
  since there is a vertical asymptote at $x=0$. 

  \begin{proof}
    Let $\{u_n\} = \frac{1}{n}$ and $\{v_n\} = \frac{2}{n}$. Note that $\{u_n - v_n\} \to 0$ but 
    \[\{f(u_n) - f(v_n)\} = \{f(\frac{1}{n}) - f(\frac{2}{n})\} = \{n - \frac{n}{2}\} = \{\frac{n}{2}\} \to \infty\]
  \end{proof}

  But now consider $f: (2, 3) \to \RR, f(x) = \frac{1}{x}$. This is uniformly continuous.

  \begin{proof}
    Suppose $\{u_n - v_n\} \to 0$ for $\{u_n\}$ and $\{v_n\}$ in $(2,3)$. 
    \[|f(u_n) - f(v_n)| = |\frac{1}{u_n} - \frac{1}{v_n}| = |\frac{u_n - v_n}{u_n v_n}|\]
    We need to bound the product $u_nv_n$. Note that $u_n > 2, v_n > 2 \implies \frac{1}{u_n} < \frac{1}{2}, \frac{1}{v_n} < \frac{1}{2}$, 
    so 
    \[< \frac{|u_n - v_n|}{2 * 2}\]
    so $|f(u_n) - f(v_n)| \leq \frac{1}{4}|u_n - v_n|$ and so by Comparison Lemma, $\{f(u_n) - f(v_n)\} \to 0$.
    Note that this would work for domains $(0.00000001, \infty)$.
  \end{proof}
\end{example}

\begin{note}
  If $f: D \to \RR$ is uniformly continuous then it is continuous, but not all 
  continuous functions are uniformly continuous. The go-to example is 
  $f(x) = x^2$ on $\RR$.
\end{note}

\begin{theorem}
  Every continuous function on a closed bounded interval $f: [a,b] \to \RR$ is uniformly continuous.

  \begin{remark}
    For example, $f(x) = x^2$ on $[a, b]$ is uniformly continuous.
  \end{remark}

  \begin{proof}
    Let $\{u_n\}, \{v_n\} \subset [a,b]$ with $\Lim (u_n - v_n)= 0$. We WTS that 
    $\Lim (f(u_n) - f(v_n)) = 0$. By contradiction, assume that $\{f(u_n) - f(v_n)\} \not \to 0$. 
    Therefore, 
    \[\exists \ \epsilon > 0 \text{ s.t. } \ \forall \ N \in \NN, \text{ there is } n \geq N\] with 
    \[|f(u_n) - f(v_n)| \geq \epsilon\]
    Let us create a subsequence
    \[n_1 \geq N = 1 \text{ s.t. } |f(u_{n_1}) - f(v_{n_1})| \geq \epsilon\]
    \[n_2 \geq n_1 + 1 \cdots |f(u_{n_2}) - f(v_{n_2})| \geq \epsilon\]
    \[n_3 \geq n_2 + 1 \cdots |f(u_{n_3}) - f(v_{n_3})| \geq \epsilon\]
    So $\{f(u_{n_k}) - f(v_{n_k})\}$ is a subsequence with 
    $\{f(u_{n_k}) - f(v_{n_k})\} \geq \epsilon \ \forall n_k$. Because $\{u_n\}$ is a 
    sequence in $[a, b]$, we can use Sequential Compactness to find a subsequence 
    $\{u_{m_k}\}$ that converges to some $x_0 \in [a,b]$. 
    Since $f$ is continuous, then $\underset{k\to\infty}{\lim} f(u_{m_k}) = f(x_0)$.
    Since $\underset{k\to\infty}{\lim}(u_n - v_n) = 0 \implies \underset{k\to\infty}{\lim}(u_{m_k} - v_{m_k}) = 0$
    by a theorem. Thus, 
    \[\lim_{k\to\infty} v_{m_k} = \lim_{k\to\infty}u_{m_k} - \lim_{k\to\infty}(u_{m_k} - v_{m_k}) = x_0 - 0 \implies \{v_{m_k}\} \to x_0\]
    Therefore, 
    \[\lim_{k\to\infty}(f(u_{m_k}) - f(v_{m_k})) = f(x_0) - f(x_0) = 0\]
    But this is a contradiction that
    \[\ \forall \ n_k, \ |f(u_{n_k}) - f(v_{n_k})| \geq \epsilon\]
    and so therefore, $\{f(u_n) - f(v_n) \to 0\}$ as desired.
  \end{proof}
\end{theorem}

\subsection{Epsilon-Delta Criterion}

\begin{definition}
  A function $f: D \to\RR$ is said to satisfy the \vocab{$\epsilon-\delta$ criterion} at $x_0 \in D$ 
  if $\ \forall \ \epsilon > 0, \ \exists \ \delta > 0$ so that 
  \[\forall \ x \in D \text{ and } |x-x_0| < \delta \implies |f(x) - f(x_0)| < \epsilon\]
\end{definition}

\begin{note}
  $\delta$ depends on $\epsilon$ and maybe $x_0$. For uniform continuity, however, $\delta$ 
  cannot depend on location, so $\delta$ will not depend on $x_0$ in the case of 
  uniform continuity.
\end{note}

\begin{example}
  $f: \RR \to \RR, f(x) = 3x$. Prove it satisfies $\epsilon-\delta$ criteria at 
  $x_0 = 2$. 

  \begin{proof}[Sketch.]
    Given $|x - 2| < \delta$. How do we show that $|f(x) - f(2)| < \epsilon$. 
    \[|3x-6| \implies |3(x-2)| < 3\delta\]
    so we take $\delta = \frac{\epsilon}{3}$. 
  \end{proof}

  \begin{proof}
    Let $\epsilon > 0$ be given. Let $x_0 = 2$ and let $\delta = \frac{\epsilon}{3}$. 
    Then if $|x-2| < \delta$ then 
    \[|f(x) - f(x_0)| = |3x-6| = 3|x-2| < 3\delta = 3 * \frac{\epsilon}{3} = \epsilon\]
  \end{proof}
\end{example}

\begin{example}
  
  $f: \RR\to\RR, f(x) = x^2$ at any $x_0$. Show $\epsilon-\delta$ criterion.

  \begin{proof}[Sketch]
    $|x-x_0| < \delta \implies |f(x) - f(x_0)| < \epsilon$
    \[|x^2 - x_0^2| = |x-x_0||x+x_0| \leq \delta |x + x_0|\]
    Note the absolute value term is constant, but $x$ could be large, so we need to bound it. 
    Let $\delta \leq 1$. What happens to $|x + x_0|$ in this case, let's try and relate it to 
    $|x-x_0|$. 
    \[|x + x_0| = |x - x_0 + x_0 + x_0| \leq |x-x_0| + |x_0 + x_0| = |x-x_0| + 2|x_0|\]
    \[\leq \delta + 2|x_0| \leq 1 + 2|x_0|\]
    which is a constant as desired. 
  \end{proof}

  \begin{proof}
    Let $\epsilon > 0$ and $x_0\in\RR$. Let $\delta = \min(1, \frac{\epsilon}{1 + 2|x_0|})$. Note that 
    $\epsilon > 0$ and $1 + 2|x_0| > 0$ and so we confirm $\delta > 0$. Thus, 
    \[\delta \leq 1 \text{ and } \delta \leq \frac{\epsilon}{1 + 2|x_0|}\]
    Then
    \[|x + x_0| = |x -x_0 + x_0 + x_0| \leq |x-x_0| + 2|x_0| \leq \delta + |2x_0| \leq 1 + 2|x_0|\]
    since $|x-x_0| < \delta$. Thus, 
    \[|f(x) - f(x_0)| = |x^2 - x_0^2| = |(x-x_0)(x+x_0)| < \delta |x+x_0| \leq \delta (1 + 2|x_0|)\]
    Recall that $\delta \leq \frac{\epsilon}{1 + 2|x_0|}$ and so 
    \[\delta (1 + 2|x_0|) \leq \frac{\epsilon}{1 + 2|x_0|}(1 + 2|x_0|) = \epsilon \implies |f(x) - f(x_0)| < \epsilon\]
  \end{proof}
\end{example}

\begin{theorem}
  Given $f: D \to \RR, x_0 \in D$, $f$ is continuous at $x_0$ iff $f$ satisfies the 
  $\epsilon-\delta$ criteria at $x_0$. Note that here $\delta$ depends on 
  $\epsilon$ and can depend on $x_0$ because we are talking about \vocab{continuity}.
\end{theorem}

\begin{definition}
  We say $f: D \to \RR$ satisifes the \vocab{$\epsilon-\delta$ criterion on $D$} if 
  \[\forall \ \epsilon > 0 \ \exists \ \delta > 0 \text{ s.t. } \ \forall \ u, v \in D, \text{ if } |u-v| < \delta \implies |f(u) - f(v)| < \epsilon\]

  Note here that $\delta$ can only depend on $\epsilon$ and not $x_0$. 

\end{definition}

\begin{theorem}
  Given $f: D \to \RR$, $f$ is uniformly continuous on $D$ iff $f$ satisfies 
  $\epsilon-\delta$ critera on $D$, and here, note that $\delta$ can only depend on 
  $\epsilon$ because we are talking about \vocab{uniform continuity}.
\end{theorem}

\subsection{Images, Inverses, Monotone Functions}

\begin{definition}
  $f: D \to \RR$ is called \vocab{monotonically increasing (decreasing)} if
  \[\forall \ u, v \in D, u < v \implies f(u) \leq (\geq) f(v)\]

  If "strictly", then the operators become $<$ and $>$ respectively. 
\end{definition}

\begin{definition}
  $f: D \to \RR$ is called \vocab{one-to-one (1-1)} when $f(u) = f(v) \implies u = v$. 
\end{definition}

\begin{definition}
  When $f$ is $1-1$, its inverse, denoted $f^{-1}(x)$ is a function from 
  $f(D)$ to $D$ satisfying $f(x) = y \leftrightarrow f^{-1}(y) = x$

  \begin{itemize}
    \item $f^{-1}(f(x)) = y \ \forall \ x \in D$
    \item $f(f^{-1}(x)) - y \ \forall \ y \in f(D)$
  \end{itemize}

\end{definition}

\begin{theorem}
  Any strictly monotone function $f: D \to \RR$ is $1-1$ and thus has an inverse. 

  \begin{proof}
    WLOG, suppose $f$ is strictly increasing and $f(u) = f(v)$. To show $1-1$, we WTS 
    $u = v$ for $u, v \in D$. By contradiction, if $u < v$, since $f$ is strictly monotone 
    increasing, then $f(u) < f(v)$. If $u > v \implies f(u) > f(v)$ by definition 
    of strictly monotonically increasing function. Therefore, $u = v$, and so 
    $f(u) = f(v) \implies u = v$ and so $f$ is 1-1.
  \end{proof}
\end{theorem}

\begin{example}
  Prove that the inverse of $f(x) = x^3$ is continuous.

  \begin{proof}
    Note that $f$ is a polynomial and thus continuous. $f$ is strictly increasing. 
    \[u < v \implies u^3 < v^3 = u * u * u < v * v * v\]
    by properties of inequalities. By a previous theorem, since $f$ is strictly increasing, 
    $f$ has an inverse. Let $x_0 \in \RR$, let $\{x_n\}\in \RR$ such that $\{x_n\} \to x_0$. 
    We WTS that $f^{-1}(x_n) \to f^{-1}(x_0)$. 

    \hfill

    For notation: label $y_n = f^{-1}(x_n), y_0 = f^{-1}(x_0)$. 
    Therefore
    \[x_n = f(y_n) = y_n^3 \]
    \[x_0 = f(y_0) = y_0^3\]
    Since $x_n \to x_0$, then $y_n^3 \to y_0^3$. We WTS $y_n \to y_0$. Let $\epsilon > 0$. 
    Let $\delta = \min((y_0+\epsilon)^3 - (y_0)^3, y_0^3 - (y_0 - \epsilon)^3)$. Since $\epsilon > 0$, 
    it is easy to show that $\delta > 0$. 

    Since 
    \[y_n^3 \to y_0^3, \ \exists \ N \text{ s.t. } \ \forall \ n \geq N, |y_n^3 - y_0^3| < \delta\]
    We know this is true for all $\epsilon$, so therefore we can let $\epsilon = \delta$. 
    \[-\delta < y_n^3 - y_0^3 < \delta \]
    \[y_0^3 - \delta < y_n^3 < \delta + y_0^3\]
    \[y_0^3 - (y_0^3 - (y_0 - \epsilon)^3) < y_n^3 < (y_0 + \epsilon)^3 - y_0^3 + y_0^3\]
    \[(y_0 - \epsilon)^3  < y_n^3 < (y_0 + \epsilon)^3\]
    \[y_0 - \epsilon < y_n < y_0 + \epsilon\]
    \[|y_n - y_0| < \epsilon\]
    and so $y_n \to y_0$ or $f^{-1}(x_n) \to f^{-1}(x_0)$ by definition of $y_n, y_0$ and so $f^{-1}(x)$ is continuous.
  \end{proof}
\end{example}

\begin{theorem}
  Let $f: D \to \RR$ is monotone. If its image is an interval, then $f$ is continuous.
  \begin{proof}
    Let $x_0 \in D$ and $\{x_n\} \in D$ with $x_n \to x_0$. Suppose on the contrary that 
    $f(x_n) \not\to f(x_0)$. Then $\ \exists \epsilon > 0$ and subsequence of $x_n$ such that 
    \[|f(x_{n_k}) - f(x_0)| \geq \epsilon\]
    Assume WLOG that $f$ is increasing. 

    Case 1: If the absolute value is positive
    \[f(x_{n_k}) - f(x_0) \geq \epsilon\]
    \[f(x_{n_k}) \geq \epsilon + f(x_0)\]
    \[f(x_{n_k}) \geq \epsilon + f(x_0) > \frac{\epsilon}{2} + f(x_0) > f(x_0)\]
    Since the image of $f$ is an interval (all points in between). So $\exists \ c \in D$ such that 
    \[f(c) = f(x_0) + \frac{\epsilon}{2}\]
    \[f(x_{n_k}) > f(c) > f(x_0)\]
    And since $f$ is strictly monotone increasing, so $x_{n_k} > c > x_0$
    \[|x_{n_k} - x_0| > |c - x_0| > 0\]
    Note that $c - x_0$ is a constant, and so $x_{n_k} \not\to x_0$.

    Case 2: If the absolute value is negative

    \[f(x_0) - f(x_{n_k}) \geq \epsilon\]
    \[f(x_0) - \epsilon \geq f(x_{n_k})\]
    \[f(x_0) > f(x_0) - \frac{\epsilon}{2} > f(x_{n_k})\]
    \[\exists \ c_2 \in D \text{ such that } f(c_2) = f(x_0) - \frac{\epsilon}{2}\]
    Since $f$ is strictly monotonically increasing, we know 
    \[x_0 > c_2 > x_{n_k}\]
    \[|x_{n_k} - x_0| > |x_0 - c_2| > 0\]
    Therefore, combining the conclusions from the two cases:
    \[x_{n_k} > \min(|x_0 - c|, |x_0 - c_2|) > 0\]
    and so therefore, $|x_{n_k}| \not\to x_0$
    which is a contradiction. Therefore, $f$ is continuous.
  \end{proof}
\end{theorem}

\begin{theorem}
  Suppose $I$ is an interval and $f: I \to \RR$ is monotone. Then $f$ is continuous
  if and only if its image is an interval.

  \begin{proof}
    Omitted. This proof follows from the IVT and the previous theorem.
  \end{proof}
\end{theorem}

\begin{theorem}
  Let $f: I \to \RR$, I is an interval, be strictly monotone. Then its inverse 
  $f^{-1}: f(I) \to \RR$ is continuous. Similar to the $x^3$ example above.
\end{theorem}

\begin{example}
  $f: [0, \infty) \to \RR$ with $f(x) = x^n$ is strictly increasing, so inverse 
  is continuous. Notation: negative integer $n$: $x^n = \frac{1}{x^{-n}}$
  \begin{itemize}
    \item $x^n * x^m = x^{n + m}$
    \item $(x^n)^m) = x^{nm}$
  \end{itemize}
  $y^{\frac{1}{n}} = f^{-1}(y^n) \ \forall \ y \geq 0$, "nth root of $y$".
\end{example}

\begin{definition}
  For $x > 0$ and $r \in \QQ$ with $r = \frac{m}{n}, m \in \ZZ, n \in \NN$, we define 
  \[x^r = (x^m)^{\frac{1}{n}}\]
\end{definition}

\begin{remark}
  Let $r \in \QQ$ and define $f(x) = x^r \ \forall \ x \geq 0$. Then $f: [0, \infty) \to \RR$ is 
  continuous. 
\end{remark}

\subsection{Limits}

\begin{note}
  Note that before $\Lim a_n = a$ for sequences but now $\underset{x\to a}{\lim}f(x) = L$
\end{note}

\begin{definition}
  We say $x_0 \in \RR$ is a \vocab{limit point} of $D$ if $\exists \ \{x_n\} \in (D - \{x_0\})$
  and $\{x_n\} \to x_0$.
\end{definition}

\begin{example}
  For $(0, 1)$, the numbers $0$ and $1$ are limit points.
\end{example}

\begin{definition}
  Given $f: D \to \RR$ and limit point $x_0$, we write 
  \[\lim_{x\to x_0} f(x) = l\]
  if whenever $\{x_n\} \in (D - \{x_0\})$ with $x_n \to x_0$ has $\Lim f(x_n) = l$
\end{definition}

\begin{remark}
  A function is continuous at $x_0$ if and only if $\underset{x\to x_0}{\lim}f(x) = f(x_0)$
\end{remark}

\begin{example}
  $\underset{x \to 2}{\lim}\sqrt{\frac{3x + 3}{x^3 - 4}}$. Note that there are no 
  denominator issues at $x = 2$. 

  \begin{proof}[Solution]
    Note that numerator and denominator are both continuous, and so the 
    quotient continuous as well because the denominator is also not $0$. 
    Further note that $\sqrt{x}$ is continuous because it is the inverse 
    of a strictly monotone function (on the domain $[0, \infty)$). Compositions of continuous functions 
    are continuous at $x=2$. So 
    \[\lim_{x\to2} = \sqrt{\frac{3x+3}{x^3-4}} = \sqrt{\frac{3(2) + 3}{2^3-4}} = \sqrt{\frac{9}{4}} = \frac{3}{2}\]
  \end{proof}
\end{example}

\begin{example}
  $\underset{x\to1}{\lim}\frac{x^2-1}{x-1}$. 

  Note that we cannot use the quotient property like above. Let $\{x_n\} \to 1$ with 
  $x_n \neq 1$. 
  \[\frac{x_n^2 - 1}{x_n - 1} = \frac{(x_n-1)(x_n+1)}{x_n-1} = x_n + 1\]
  So therefore
  \[\lim_{x\to1} \frac{x^2-1}{x-1} = \lim_{n\to\infty}\frac{x_n^2-1}{x_n-1} = \lim_{n\to\infty}x_n + 1 = 1 + 1 = 2\]
\end{example}

\begin{theorem}
  $f: D \to \RR$ and $g: D \to \RR, x_0 \in\RR$ is a limit point. 
  Let $\underset{x\to x_0}{\lim}f(x) = A$ and $\underset{x\to x_0}{\lim}g(x) = B$
  and $c \in \RR$. Then 
  \begin{enumerate}[i.]
    \item $\underset{x\to x_0}{\lim}(f(x) \pm g(x)) = A \pm B$
    \item $\underset{x\to x_0}{\lim}(f(x)g(x)) = A \cdot B$
    \item $\underset{x\to x_0}{\lim}\frac{f(x)}{g(x)} = \frac{A}{B}, g(x) \neq 0, B \neq 0$
    \item $\underset{x\to x_0}{\lim}cf(x) = cA$
  \end{enumerate}
  These follow directly from properties of sequences. Similarly for compositions.
  $f: D \to \RR, g: U \to \RR, x_0$ is a limit point with $\underset{x\to x_0}{\lim}f(x) = y_0$
  and $\underset{y\to y_0}{\lim}g(y) = l$ and $f(D - \{x_0\}) \subset U - \{y_0\}$. 
  Then
  \[\lim_{x\to x_0} (g \circ f)(x) = l\]
  We will see limits later on in Differentiation.
\end{theorem}

\section{Differentiation}

\subsection{Basic Differentiation Rules}

\begin{remark}
  High level: to find the tangent line, take a sequence of secant lines closer and 
  closer towards $x$
  \[\lim_{x\to x_0}\frac{f(x) - f(x_0)}{x - x_0} = m_0 \ \ \ \text{(slope)}\]
\end{remark}

\begin{definition}
  For $x_0 \in \RR$, the open interval $I = (a, b)$  that contains $x_0$ 
  is called a \vocab{neighborhood} of $x_0$. 
\end{definition}

\begin{definition}
  $f: I \to \RR$ is said to be \vocab{differentiable at $x_0$} if
  \[\underset{x\to x_0}{\lim}\frac{f(x) - f(x_0)}{x - x_0} := f'(x_0)\] exists 
  and we denote it by $f'(x_0)$, the \vocab{derivative} of $f$ at $x_0$.  
\end{definition}

\begin{remark}
  If $f$ is differentiable at every point in $I$, $f$ is \vocab{differentiable} and 
  $f': I \to \RR$ is called the \vocab{derivative}.
\end{remark}

\begin{example}
  $f(x) = mx + b$. Find $f'$.
  \[f'(x_0) = \lim_{x\to x_0}\frac{f(x) - f(x_0)}{x - x_0} = \lim_{x\to x_0}\frac{mx + b - mx_0 - b}{x - x_0} = m\]
\end{example}

\begin{example}
  $f(x) = x^2$. Find $f'$.
  \[f'(x_0) = \lim_{x\to x_0}\frac{f(x) - f(x_0)}{x - x_0} = \lim_{x\to x_0}\frac{x^2 - x_0^2}{x - x_0} = \lim_{x \to x_0} \frac{(x- x_0)(x+x_0)}{x-x_0} = 2x_0\]
\end{example}

\begin{note}
  \[(x^2 - x_0^2) = (x-x_0)(x+x_0)\]
  \[(x^3 - x_0^3) = (x-x_0)(x^2 + xx_0 + x_0^2)\]
  \[(x^4 - x_0^4) = (x-x_0)(x^3 + x^2x_0 + xx_0^2 + x_0^3)\]
  Notice the pattern. Binomial Expansion. Note that you can prove this general 
  pattern using induction.
\end{note}

\begin{example}
  $f(x) = x^n, n \in \NN$. Find $f'$. \vocab{Power Rule}.
  \[f'(x_0) = \lim_{x\to x_0}\frac{x^n - x_0^n}{x - x_0} = \lim_{x\to x_0}\frac{(x-x_0)(\cdots)}{x - x_0}\]
  where $x \neq x_0$. 
  \[= x_0^{n-1} + x_0^{n-2}x_0 + x_0^{n-3}x_0^2 + \cdots + x_0^{n-1}\]
  \[= n x_0^{n-1}\]
\end{example}

\begin{theorem}
  If $f: I \to \RR$ is differentiable at $x_0$, $f$ is continuous at $x_0$.

  \begin{proof}
    Since $f$ is differentiable at $x_0$: 
    \[f'(x_0) = \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x - x_0}\]
    exists and we have $\underset{x\to\infty}{\lim}(x-x_0) = 0$. We WTS that $\underset{x\to\infty}{\lim}(f(x) - f(x_0)) = 0$. 
    Thus, \[\underset{x\to x_0}{\lim}{(f(x) -  f(x_0))} = \lim_{x\to x_0}\frac{f(x) - f(x_0)}{x-x_0} * (x-x_0) = f'(x_0) * 0 = 0\]
    as needed, so $f$ is continuous at $x_0$.
  \end{proof}
\end{theorem}

\begin{note}
  Differentiability implies continuity, but continuity doesn't imply differentiability, and the 
  classical example to show this is $f(x) = |x|$. 
\end{note}

\begin{theorem}
  If $f: I \to \RR, g: I \to \RR$, both differentiable at $x_0$ then 
  \begin{enumerate}[a.]
    \item $(f \pm g)'(x_0) = f'(x_0) +\pm g'(x_0)$
  \[\lim_{x\to x_0}\frac{(f\pm g)(x_0) - (f\pm g)(x_0)}{x - x_0} = \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x - x_0} \pm \lim_{x\to x_0}\frac{g(x) - g(x_0)}{x - x_0}\]
  \[= f'(x_0) \pm g'(x_0)\]

    \item $(fg')(x_0) = f'(x_0)g(x_0) + f(x_0)g'(x_0)$
    
  \[\lim_{x\to x_0}\frac{(fg)(x) - (fg)(x_0)}{x - x_0} = \lim_{x\to x_0}\frac{f(x)g(x) - f(x_0)g(x_0)}{x - x_0}\]
  \[= \lim_{x\to x_0}\frac{f(x)g(x) - f(x_0)g(x) + f(x_0)g(x) - f(x_0)g(x_0)}{x - x_0}\]
  \[= \lim_{x\to x_0}g(x)\frac{f(x) - f(x_0)}{x - x_0} + \lim_{x\to x_0} f(x_0)\frac{g(x) - g(x_0)}{x-x_0}\]
  Note that since $g$ is differentiable at $x_0$, $g$ is continuous at $x_0$, and 
  so $\underset{x\to x_0}{\lim}g(x) = g(x_0)$. Therefore, we get 
  \[= g(x_0)f'(x_0) + f(x_0)g'(x_0)\]

    \item $(\frac{f}{g})'(x_0) = \frac{f'(x_0)g(x_0) - f(x_0)g'(x_0)}{(g(x_0))^2}$
  
  Before quotient rule, we wil prove $(\frac{1}{g})' = -\frac{g'(x_0)}{(g(x_0))^2}$
    \[\lim_{x\to x_0} \dfrac{(\frac{1}{g})(x) - (\frac{1}{g})(x_0)}{x-x_0} = \lim_{x\to x_0 }\dfrac{\frac{1}{g(x)} -  \frac{1}{g(x_0)}}{x-x_0} = \lim_{x\to x_0}\frac{\frac{g(x_0) - g(x)}{g(x_0)g(x)}}{x-x_0}\]
    Note that $g$ is differentiable at $x_0$, so it is continuous at $x_0$, and so 
    $\underset{x\to x_0}{\lim}g(x) = g(x_0)$
    \[\lim_{x\to x_0}-\frac{1}{g(x_0)g(x)}\frac{g(x) - g(x_0)}{x - x_0} = -\frac{1}{g(x_0)^2}g'(x_0)\]
  Now for the quotient rule, observe that 
  \[(\frac{f(x_0)}{g(x_0)})' = (\frac{1}{g(x_0)} \cdot f(x_0))'\]
  Using above and the product rule, we get 
  \[-\frac{1}{g(x_0)^2}g'(x_0) f(x_0) + f'(x_0)\frac{1}{g(x_0)} = \frac{f'(x_0)g(x_0) - g'(x_0)f(x_0)}{g(x_0)^2}\]
  \end{enumerate}
\end{theorem}

\begin{note}
  Power rule works for negative powers too. We know thart $f(x) = x^n, n \in \NN$ s.t. $f'(x) = nx^{n-1}$.

  Let $g(x) = x^n = \frac{1}{x^{-n}}, n < 0$. So, 
  \[(\frac{1}{x^{-n}})' \underset{(*)}{=} -\frac{(x^{-n})'}{(x^{-n})^2} = -\frac{(-nx^{-n-1})}{x^{-n}x^{-n}} = nx^{n-1}\]
\end{note}

\subsection{Differentiating Inverses and Compositions}

\begin{example}
  $f: [0, \infty) \to \RR$ such that $f(x) = x^2$ and therefore $f^{-1}(y) = \sqrt{y}$.

  Look at the point $x=3, y=9$, $f'(x) = 2x, f'(3) = 6$. Is the derivative of the 
  inverse at $y=9$ equal to $\frac{1}{6}$. Yes!  

  \[\lim_{y \to 9} \frac{f^{-1}(y) - f^{-1}(y_0)}{y - y_0} = \lim_{y\to 9}\frac{\sqrt{y} - 3}{y - 9} = \lim_{y\to 9} \frac{1}{\sqrt{y} + 3} = \frac{1}{6}\]
  as desired.
\end{example}

\begin{theorem}
  Let $f: I \to \RR$ be strictly monotone and continuous. 
  Suppose $f$ is differentiable at $x_0$ and $f'(x_0) \neq 0$. 
  Define $J = f(I)$. Then $f^{-1}: J \to \RR$ is differentiable at $y_0 = f(x_0)$ 
  and
  \[(f^{-1})'(y_0) = \frac{1}{f'(x_0)}\]

  \begin{proof}
    Note that $J$ is also a neighborhood of $y_0 = f(x_0)$ by IVT.
    For $y \in J, y \neq y_0$, define $f^{-1}(y) = x$. Then 
    \[\frac{f^{-1}(y) - f^{-1}(y_0)}{y - y_0} = \frac{x-x_0}{f(x) - f(x_0)} = \frac{1}{\frac{f(x) - f(x_0)}{x-x_0}}\]
    Note that $f^{-1}$ is differentiable, and so it is continuous, and so 
    \[\lim_{y\to y_0}f^{-1}(y) = f^{-1}(y_0) = x_0\]
    Now applying the limits, we get 
    \[\lim_{y\to y_0}\frac{f^{-1}(y) - f^{-1}(y_0)}{y-y_0} = \lim_{y\to y_0}\frac{1}{\frac{f(x) - f(x_0)}{x-x_0}} = \frac{1}{f'(x_0)}\]
    Therefore, $f^{-1}$ is differentiable at $y_0$ and
    \[(f^{-1})'(y_0) = \frac{1}{f'(x_0)}\]
  \end{proof}
\end{theorem}

\begin{corollary}
  For functions in general, suppose $f: I \to \RR$ is strictly monotone and differentiable and 
  $f'(x) \neq 0 \ \forall \ x$. Define $J = f(I)$. Then 
  $f^{-1}: J \to \RR$ is differentiable and
  \[(f^{-1})'(x) = \frac{1}{f'(f^{-1}(x))} \ \forall \ x \in J\] 
  Take $x = f(f(^{-1})(x))$ and $f^{-1}(x) \to x_0$.
\end{corollary}

\begin{lemma}
  For $n \in \NN, g(x) = x^{1/n}, g: (0, \infty) \to \RR$. Claim 
  $g$ is differentiable and $g'(x) = \frac{1}{n}x^{1/n - 1}$.
  \begin{proof}[Sketch of a Proof]
    Suppose $f(x) = x^n$ and so we know the inverse is $g(x) = x^{1/n}$. We know 
    $f'(x) = nx^{x-1}, n \in \NN$. From the corollary above, 
    \[g'(x) = \frac{1}{f'(g(x))} = \frac{1}{n(x^{1/n})^{n-1}} = \frac{1}{n(x^{1-1/n})} = \frac{1}{n}x^{\frac{1}{n} - 1}\]
    as desired.
  \end{proof}
\end{lemma}

\begin{theorem}
  The \vocab{Chain Rule}. Let $I$ be a neighborhood of $x_0$, 
  $f: I \to \RR$ differentiable at $x_0$, $J$ is an open interval such that 
  $f(I) \subset J$, $g: J \to \RR$ is differentiable at $f(x_0)$. Then 
  \[(g \circ f): I \to \RR \text{ is differentiable at } x_0\] and 
  \[(g \circ f)'(x_0) = g'(f(x_0))\ \cdot f'(x_0)\]
  \begin{proof}
    Proof omitted in class.
  \end{proof}
\end{theorem}

\begin{example}
  Let $r = \frac{m}{n}, m \in \ZZ, n \in \NN$ and define 
  $f(x) = x^m$ and $g(x) = x^{1/n}$ and so 
  $f'(x) = mx^{m-1}$ and $g'(x) = \frac{1}{n}x^{1/n - 1}$. Let 
  $h(x) = f(g(x))$. Then using the Chain Rule, 
  \[h'(x) = g'(f(x))f'(x) = \frac{1}{n}(x^m)^{1/n - 1} \cdot mx^{m-1}\]
  \[= \frac{m}{n}x^{\frac{m}{n} - m + m - 1} = \frac{m}{n}x^{m/n - 1} = rx^{r- 1}\]
  as needed.
\end{example}

\subsection{Rolle's Theorem and Mean Value Theorem}

\begin{definition}
  $x_0 \in D$ of $f: D \to \RR$ is said to be a \vocab{local max (min)} if $\ \exists$ a neighborhood 
  $I$ of $x_0$ for which $f(x_0) \geq f(x) \ (f(x_0) \leq f(x)) \ \forall \ x \in I \cap D$
\end{definition}

\begin{lemma}
  Suppose $f: I \to \RR$ is differentiable at $x_0$. If 
  $x_0$ is either a max or min of $f$, then $f'(x_0) = 0$. 

  \begin{proof}
    Let $x_0$ be a max WLOG. Then $f(x) \leq f(x_0) \ \forall \ x$ by 
    definition of max at $x$. Consider $x < x_0$ in $x \in I$. Then 
    \[\frac{f(x) - f(x_0)}{x-x_0} \geq 0\]
    Note that the numerator is negative and the denominator is negative. Therefore, the entire 
    expression is positive. Now if $x > x_0$, then 
    \[\frac{f(x) - f(x_0)}{x-x_0} \leq 0\]
    But in order for the derivative (limit) to exist, then for all 
    sequences, the image sequences must converge to the same value. Therefore, 
    \[f'(x_0) = \lim_{x\to x_0, x < x_0} \frac{f(x) - f(x_0)}{x-x_0} \geq 0\]
    \[ = \lim_{x\to x_0, x > x_0} \frac{f(x) - f(x_0)}{x -x_0} \leq 0\]
    \[\implies f'(x_0) = 0\]
    in order for the derivative to exist.
  \end{proof}
\end{lemma}

\begin{theorem}
  \vocab{Rolle's Theorem} says suppose there is a function $f: [a,b] \to \RR$ is 
  continuous and $f: (a, b) \to \RR$ is differentiable, and $f(a) = f(b)$, then 
  \[\exists \ x_0 \in (a,b) \text{ such that } f'(x_0) = 0\]

  \begin{proof}
    Let $f(a) = f(b)$. Since $f: [a,b] \to \RR$ is continuity, apply the 
    EVT, so $f$ attains max and min value on $[a,b]$. If both the 
    min/max occur at endpoints, then the function $f$ must be constant, and so 
    $f'(x) = 0$ at every point $x$ in $(a,b)$. Otherwise, the 
    min/max are in $I = (a,b)$ and apply the previous lemma. 
  \end{proof}
\end{theorem}

\begin{theorem}
  The \vocab{Mean Value Theorem (MVT)} states that suppose $f: [a,b]\to \RR$ is 
  continuous and $f: (a,b)\to\RR$ is differentiable. Then 
  \[\exists \ x_0 \in (a,b) \text{ such that } f'(x_0) = \frac{f(b) - f(a)}{b-a} \text{ (slope) }\]
  \begin{proof}
    Let $m = \frac{f(b) - f(a)}{b - a}$. For any $m$, apply 
    Rolle's Theorem to $h: [a,b]\to\RR$ defined by $h(x) = f(x) -mx \implies h'(x) = f'(x) - m$. 
    Note that $h$ is continuous on $[a,b]$ since $f(x)$ and 
    $-mx$ are continuous (cont + cont = cont) from chapter 3. 
    Similarly, $h$ is differnetiable on $(a,b)$ since 
    $f$ and $-mx$ are diff (diff + diff = diff) from chapter 4. Now we need to check if 
    $h(a) = h(b)$. 
    \[h(a) = f(a) - ma = f(a) - (\frac{f(b) - f(a)}{b-a})a = \frac{f(a)(b-a) - f(b)a + f(a)a}{b-a}\]
    \[= \frac{f(a)b - f(a)a - f(b)a + f(a)a}{b-a} = \frac{f(a)b - f(b)a}{b-a}\]
    Similarly, $h(b) = \frac{f(a)b - f(b)a}{b-a}$, it is the same algebra. 
    Therefore, $h(a) = h(b)$ and so we can apply Rolle's Theorem and 
    so $\ \exists \ x_0 \in (a,b)$ with $h'(x_0) = 0$. Thus, 
    \[f'(x_0) - m = 0 \implies f'(x_0) = m = \frac{f(b) - f(a)}{b-a}\]
    as desired.
  \end{proof}
\end{theorem}

\begin{example}
  Prove that $x^3 + 3x + 1$ has a unique solution.

  \begin{proof}[Solution]
    Let $f(x) = x^3 + 3x + 1$. Note that $f$ is continuous because 
    it is a polynomial, and $f$ is differentiable. Note that 
    $f(0) = 1 > 0$ and $f(-1) = -3 < 0$. Since $0 \in (-3, 1)$, by the IVT, 
    $\exists x_0 \in (-1, 0) \text{ such that } f(x) = 0$. Is it unique?
    Assume not and assume there are $2$ solutions such that 
    \[f(a) = 0 = f(b)\]
    By Rolle's Theorem $\exists c \in (a,b) \text{ such that } f'(c) = 0$
    But $f'(x) = 3x^2 + 3$ and so 
    \[f'(c) = 3c^2 + 3 = 0 \implies 3c^2 = -3 \implies c^2 = -1\]
    which is not a real number, so it is a contradiction and therefore there must 
    only be one solution.
  \end{proof}
\end{example}

\begin{remark}
  The MVT is useful when you have information about a derivative. 
\end{remark}

\begin{definition}
  \vocab{Identity Criterion}: a function $f: D \to \RR$ is said to be 
  \vocab{constant} if $\ \exists c \in \RR$ s.t. $f(x) = c \ \forall \ x \in D$.  
\end{definition}

\begin{lemma}
  Let $f: I \to \RR$ be differentiable. Then $f$ is constant if and only if 
  $f'(x) = 0 \ \forall \ x \in D$. 
  \begin{proof}
    
    \hfill

    $\Longrightarrow$ Let $f$ be constant such that $f(x) = c, c \in \RR, \forall \ x \in I$ by definition. 
    Then $f'(x) = 0 \ \forall \ x \in I$ by derivatve rules. Done. 

    $\Longleftarrow$. Let $f'(x) = 0 \ \forall \ x \in I$. Choose 
    $x_0 \in I$ and define $c := f(x_0)$. We WTS that $f(x) = c \ \forall \ x \in I$. 
    Let $x \in I$ with $x < x_0$. Recall that differentiability implies continuity, so 
    $f: [x, x_0] \to \RR$ is continuous and $f: (x, x_0) \to \RR$ is differentiable. 
    By MVT, then $\ \exists \ z \in (x, x_0)$ with $f'(z) = \frac{f(x_0) - f(x)}{x_0 - x}$. But 
    $f'(z) = 0$ since $f'(x)=0 \ \forall \ x \in I$ by assumption. 
    \[f'(z) = 0 \implies f(x_0) - f(x) = 0 \implies c = f(x_0) = f(x)\]
    \[\implies c = f(x) \ \forall \ x \in I, x < x_0\]
    The same argument applies for $(x_0, x]$. Therefore, 
    $f(x) = c \ \forall \ x \in I$.
  \end{proof}
\end{lemma}

\begin{definition}
  \vocab{The Identity Criterion (differ by a constant)}. Let $g: I \to \RR, h: I \to \RR$ 
  both be differentiable. Then $g, h$ \vocab{differ by a constant} if and only if 
  $g'(x) = f'(x) \forall \ x \in I$. 
  \[\exists \ c \text{ s.t. } g(x) = h(x) + c\]

  \begin{proof}
    Define $f(x) = g(x) - h(x), f: I \to \RR$ and $f'(x) = g'(x) - g'(x)$. 
    Using the previous lemma, 
    \[f \text{ constant } \Longleftrightarrow f'(x) = 0\]
    \[f(x) = c \ \forall \ x \in I \Longleftrightarrow g'(x) - h'(x) = 0\]
    \[\Longleftrightarrow g(x) - h(x) = c \text{ by def'n of f}\]
    \[\Longleftrightarrow g(x) = h(x) + c\]

    Note that this gives us antiderivatives.
  \end{proof}
\end{definition}

\begin{definition}
  \vocab{The Criterion for Strict Monotonicity}. Let $f: I \to \RR$ 
  be differentiable. Suppose $f'(x) > 0 \forall \ x \in I$. Then $f: I \to \RR$ 
  is \vocab{strictly increasing}.
  
  \begin{proof}
    Let $u < v$ with $u, v \in I$. We WTS that $f(u) < f(v)$.
    Suppose $f'(x) > 0$. Apply the MVT to $f: [u, v] \to \RR$ and choose 
    $x_0 \in (u, v)$ at which 
    \[f'(x_0) = \frac{f(v) - f(u)}{v - u} > 0 \]
    since $f'(x) > 0 \ \forall \ x$. Since $u < v \implies v-u > 0$, and 
    so $f(v) - f(u) > 0 \implies f(u) < f(v)$ as needed. Similar process 
    can be shown for $f'(x) < 0$ for $f$ strictly decreasing.
  \end{proof}
\end{definition}

\begin{remark}
  Knowing $f'(x_0) = 0$ does not guarantee a local min/max. Consider 
  $f = x^3$ at $x=0$, $f'(0) = 0$ but it is not a local min/max.
\end{remark}

\begin{theorem}
  Suppose $f: I \to \RR$ has 2 derivatives $f', f''$ and $f'(x_0) = 0$. Then if 
  \begin{enumerate}[i.]
    \item $f''(x_0) > 0 \implies$ concave up, so $x_0$ is a local min of $f$
    \item $f''(x_0) < 0 \implies$ concave down, so $x_0$ is a local max of $f$
  \end{enumerate}
\end{theorem}

\subsection{Cauchy Mean Value Theorem}

\begin{theorem}
  \vocab{Cauchy Mean Value Theorem (CMVT)}. Let $f: [a,b] \to \RR, g: [a,b] \to \RR$ continuous. 
  Let $f: (a,b) \to \RR, g: (a,b) \to \RR$ be differentiable.
  $g'(x) \neq 0 \ \forall \ x \in (a,b)$. Then 
  \[\exists \ x_0 \in (a,b) \text{ s.t. } \frac{f'(x_0)}{g'(x_0)} = \frac{f(b) - f(a)}{g(b) - g(a)}\]
  \begin{proof}
    Let $m := \frac{f(b) - f(a)}{g(b) - g(a)}$. Define $h: [a,b]\to \RR$ as 
    $h(x) = f(x) - mg(x)$. Note that $h$ is continuous on $[a,b]$ 
    and differentiable on $(a,b)$ because $f$ and $g$ are. Let us 
    check that $h(a) = h(b)$. 
    \[h(a) = f(a) - mg(a) = f(a) - (\frac{f(b) - f(a)}{g(b) - g(a)})g(a)\]
    \[= \frac{f(a)g(b) - f(a)g(a) - f(b)g(a) + f(a)g(a)}{g(b) - g(a)}\]
    \[= \frac{f(a)g(b) - f(b)g(a)}{g(b) - g(a) = h(b)}\]
    where you can do similar algebra for $g(b)$ to check.
    Therefore, by Rolle's Theorem, $\exists \ x_0 \in (a,b) \text{ wtih } h'(x_0) = 0$
    but
    \[h'(x_0) = f'(x_0) - mg'(x_0) = 0\]
    \[f'(x_0) = mg'(x_0)\]
    \[\frac{f'(x_0)}{g'(x_0)} = m = \frac{f(b) - f(a)}{g(b) - g(a)}\]
    This is useful for the approximation of $f$ using polynomials. Taylor series. 
    We will see these after integrals.
  \end{proof}
\end{theorem}

\begin{theorem}
  This is an application of CMVT: Let $n \in \NN$ and $f: I \to \RR$ have 
  $n$ derivatives. Suppose at some $x_0 \in I$, 
  \[f(x_0) = f'(x_0) = f''(x_0) = \cdots = f^{(n-1)}(x_0) = 0\]
  Then $\ \forall \ x \in I$ with $x \neq x_0 \ \exists \ z \in (x, x_0) \cup (x_0, x)$
  such that 
  \[f(x) = \frac{f^{(n)}(z)}{n!}(x-x_0)^n\]
  \begin{proof}
    Let $n \in \NN$ and $f: I \to \RR$ have $n$ derivatives.
    Suppose at some $x_0 \in I$
    \[f(x_0) = f'(x_0) = f''(x_0) = \cdots = f^{(n-1)}(x_0) = 0\]
    Let $g(x) = (x-x_0)^n$. Note that 
    \[g'(x) = n(x-x_0)^{n-1}\]
    \[\vdots\]
    \[g^{(n)}(x) = n(n-1)(n-2)\cdots 2 * 1 = n!\]
    Using the CMVT for $f, g$ on $[x, x_0]$ (or $[x_0, x]$)
    since $f$ is differentiable and therefore continuous, and 
    $g(x) = (x-x_0)^n$ is polynomial so differentiable and continuous, 
    \[\exists \ c_1 \in (x, x_0) \text{ s.t. } \frac{f(x) - f(x_0)}{g(x) - g(x_0)} = \frac{f'(c_1)}{g'(c_1)}\]
    However, note that $f(x_0) = 0$ bu assumption and $g(x_0) = (x_0 - x_0)^n = 0$
    by definition of $g$. So the above becomes 
    \[\frac{f(x)}{g(x)} = \frac{f'(c_1)}{g'(c_1)}\]
    Repeating the process
    \[\frac{f(x)}{g(x)} = \frac{f'(c_1)}{g'(c_1)} = \frac{f'(c_1) - f'(x_0)}{g'(c_1) - g'(x_0)} = \frac{f''(c_2)}{g''(c_2)}\]
    for some $c_2 \in [c_1, x_0]$ 
    and then continue iterating such that 
    \[\frac{f(x)}{g(x)} = \frac{f^{(n)}(c_n)}{n!} \implies f(x) = \frac{f^{(n)}(c_n)}{n!}g(x)\]
  \end{proof}
\end{theorem}

\section{Differential Equations}

Skip this section.

\section{Integration}

\subsection{Darboux Sums and Refinement Lemma}

\begin{remark}
  Unless stated otherwise, in this chapter, $I = [a,b]$ 
  and $f: [a,b] \to \RR$ is bounded.
\end{remark}

\begin{definition}
  Let $a < b, a, b \in \RR$ and 
  \[a = x_0 < x_1 < x_2 < \cdots < x_{n-1} < x_n = b\]
  Then $P = \{x_1, x_1, x_2, \ldots, x_n\}$ is called a 
  \vocab{partition} on $[a,b]$. For all $i \geq 0$, 
  $x_i$ is called a \vocab{partition point} and $[x_{i-1}, x_i]$
  is a \vocab{partition interval}.
\end{definition}

\includegraphics[width=10cm]{partition_darboux.png}

\begin{definition}
  Let
  \[m_1 := \inf\{f(x) \ | \ x \in [x_{i-1}, x]\}\]
  \[m_2 := \sup\{f(x) \ | \ x \in [x_{i-1}, x]\}\]
  We define \vocab{Darboux Lower/Upper Sums} of $f$ on $P$ as 
  \[L(f, P) = \sum_{i=1}^n m_i (x_i - x_{i-1}) \ \text{blue above}\]
  \[U(f, P) = \sum_{i=1}^n M_i(x_i - x_{i-1}) \ \text{ green above }\]
Note that these are just the sums of areas of rectangles.
\end{definition}

\begin{note}
  Note that $m_i \leq M_i$ by definition of $\inf \leq \sup$. 
  Therefore, $L(f, P) \leq U(f, P) \ \forall \ \text{parititions of } [a,b]$. 
  The goal is to obtain 
  \[L(f, P) \leq \int_a^b f \leq U(f, P)\]
\end{note}

\begin{note}
  Given $P = \{x_0, \ldots, x_n\}$ on $[a,b]$, the 
  length of $[a,b]$ is the sum of all of the lengths of partition 
  intervals 
  \[b-a = \sum_{i=1}^n (x_i - x_{i-1})\]
\end{note}

\begin{definition}
  Given a partition of $P$ of $[a,b]$, another 
  partition $P^*$ of $[a,b]$ is called a \vocab{refinement} of $P$
  if each partition point of $P$ is also a partition point of $P^*$. $P \subseteq P^*$.
\end{definition}

\begin{lemma}
  \vocab{The Refinement Lemma} states that given paritition $P$, 
  if $P^*$ is a refinement of $P$, then 
  \[L(f, P) \leq L(f, P^*) \text{ and } U(f, P^*) \leq U(f, P)\]
  \begin{proof}
    Let $P = \{x_0, \ldots, x_n\}$. Assume $P^*$ is a refinent with 
    exactly one additional point compared to $P$ and label it $z$. 
    Note that you can iterate this process for more additional points.
    \[P^* = \{x_0, \ldots, x_{k-1}, z, z_k, \ldots, x_n\}, P^* = P \cup \{z\}\]
    Let $m_i = \inf\{f(x) \ | \ x \in [x_{i-1}, x_i]\}$ and $L(f, P) = \sum_{i=1}^n m_i(x_i - x_{i-1})$ 
    by definition. Observe that 
    \[L(f, P^*) = \sum_{i=1}^{k-1} m_i(x_i - x_{i-1}) + A(z - x_{k-1}) + B(x_k - z) + \sum_{i=k+1}^n m_i(x_i - x_{i-1})\]
    where $A = \inf\{f(x) \ | \ x \in [x_{k-1}, z]\}$ and 
    $B = \inf\{f(x) \ | \ x \in [z, x_k]\}$. Then 
    \[L(f, P^*) - L(f, P) = A(z - x_{k-1}) + B(x_k - z) - m_k(x_k - x_{k-1})\]
    and we want to show that this is $\geq 0$. Note that if $x \in [x_{k-1}, z]$ or $x \in [z, x_k]$
    then $x \in [x_{k-1}, x_k] \implies f(x) m_k$ by definition of $\inf$. 
    Therefore, $m_k$ is a lower bound for $\{f(x) \ | \ x \in [x_{k-1}, z]\}$. Therefore, 
    $m_k \leq A$ and $m_k \leq B$. 
    \[L(f, P^*) - L(f, P) = A(z-x_{k-1}) + B(x_k - z) - m_k(x_k - x_{k-1})\]
    \[\geq m_k(z-x_{k-1}) + m_k(x_k - z) - m_k(x_k - x_{k-1}) = 0\]
    \[L(f, P^*) - L(f, P) \geq 0 \implies L(f, P^*) \geq L(f, P)\]
    and similarly for Darboux Upper Sums.
  \end{proof}
\end{lemma}

\begin{corollary}
  Let $P, Q$ be parititions of $[a,b]$ then 
  $L(f, P) \leq U(f, Q)$. 

  \begin{proof}
  Consider $P \cup Q$ refinement. Then use the refinement lemma which gives us 
  \[L(f, P) \leq L(f, P \cup Q) \leq U(f, P \cup Q) \leq U(f, Q)\]
  Therefore, $L(f, P) \leq U(f, Q)$ as desired.
  \end{proof}

\end{corollary}

\begin{definition}
  For $f: [a,b] \to \RR$ such that $f$ is bounded, then 
  the \vocab{Lower Integral} is defined as 
  \[\int_{\overset{a}{\_}}^b f := \sup\{L(f, P) \ | \ \text{ P partition on } [a,b]\}\]
  and the \vocab{Upper Intergral} is defined as 
  \[\int_a^{\bar{b}} f := \inf\{U(f, P) \ | \ \text{P parition on } [a,b]\}\]
\end{definition}

\begin{lemma}
  Note that $\int_{\overset{a}{\_}}^b f \leq \int_a^{\bar{b}} f$ using 
  lower/upper sum properties.
\end{lemma}

\begin{example}
  Let $f: [a,b] \to \RR$ such that $f(x) = c$.
  Note that by geometry, the area is $c(b-a)$. Both upper 
  and lower integrals $= c(b-a)$. Since by definition
  $m_i = c, M_i = c \ \forall \ i$. So, by the sums formula, 
  \[c(b-a) = c \sum_{i=1}^n (x_i - x_{i-1}) = \sum_{i=1}^n c(x_i - x_{i-1}) = L(f, P) = U(f,P)\] 
  So
  \[\int_{\overset{\_}{a}}^b f = c(b-a) = \int_a^{\bar{b}} f\]
\end{example}

\begin{example}
  Let
  \[f(x) = \begin{cases}
    1, \ x \in \QQ\\
    0, \ x \in \QQ^c
  \end{cases}\]
  Note that this is Dirichlet's function. Let $P = \{x_0, \ldots, x_n\}$. 
  Since $\QQ$ and $\QQ^c$ are dense in each $[x_{i-1}, x_i]$, 
  then $\exists \ $ rational and irrational number in each $[x_{i-1}, x_i]$
  such that $m_i = 0, M_i = 1 \ \forall \ i$. Therefore, 
  \[L(f, P) = \sum_{i=1}^n m_i(x_i - x_{i-1}) = 0\]
  \[U(f, P) = \sum_{i=1}^n M_i (x_i - x_{i-1}) = \sum_{i=1}^n 1 (x_i - x_{i-1})\]
  \[= (x_i - x_0) - (x_2 - x_1) \cdots + (x_n - x_{n-1}) = x_n - x_0 = b - a\]
  Therefore, 
  \[\int_a^{\bar{b}} f = \inf\{b-a\} = b-a \text{ and } \int_{\overset{a}{\_}}^b f = \sup\{0\} = 0\]
\end{example}

\subsection{Integrable and Archimedes-Riemann Theorem}

\begin{definition}
  Let $f: [a,b] \to \RR$ be bounded. Then we say $f$ is 
  \vocab{integrable} on $[a,b]$ if $\lint f = \uint f$. 
  We denote the \vocab{integral} of $f$ 
  \[\int_{\overset{a}{\_}}^b f = \int_a^{\bar{b}} f = \int_a^b f\]
  Recall that 
  \[L(f, P) \leq \lint f \leq \uint f \leq U(f, P)\]
  by definition of sup, properties of Darboux sums, and then by definition of inf. 
  As a consequence, if we rearrange the above, then 
  \[0 \leq \uint f - \lint f \leq U(f, P) - L(f, P)\]
  \[0 \leq U(f, P) - \uint f \leq U(f, P) - L(f, P)\]
  \[0 \leq \lint f - L(f,P) \leq U(f, P) - L(f, P)\]
\end{definition}

\begin{theorem}
  The \vocab{Archimedes-Riemann Theorem} states that 
  suppose $f: [a,b] \to \RR$ is bounded. Then $f$ is \vocab{integrable} on 
  $[a,b]$ if and only if $\exists \ $ sequence $\{P_n\}$ of 
  partition on $[a,b]$ such that 
  \[\lim_{n\to\infty} (U(f, P) - L(f, P)) = 0\]
  Moreover, for any sequence of partitions
  \[\lim_{n\to\infty} L(f, P_n) = \int_a^b f = \lim_{n\to\infty}U(f, P_n)\]

  \begin{proof}

    \hfill

    $\Longrightarrow$ Suppose $f$ is integrable. Therefore, 
    $\lint f = \uint f = \int_a^b f \ \forall \ n \in N$.
    Note that $(\lint f) - \frac{1}{n}$ is not an upper bound for 
    $L(f, P)$ since 
    
    $\lint f = \sup\{L(f, P) \ | \ \text{P partition on [a,b]}\}$
    Therefore, $\ \exists \ $ partition $Q_n$ of $[a,b]$ such that 
    \[(\lint f) - \frac{1}{n} < L(f, Q_n)\]
    Similarly, $\exists \ $ partition $R_n$ of $[a,b]$ such that 
    \[(\uint f) + \frac{1}{n} > U(f, R_n)\]
    Let $P_n = Q_n \cup R_n$ be a refinement. Then 
    \[L(f, P_n) \geq L(f, Q_n) > \lint f - \frac{1}{n}\]
    by the Refinement Lemma and then by our definition of $Q_n$. Similarly, 
    Equivalently, if we multiply by $-1$, then see that $-L(f, P_n) \leq -(\uint f - \frac{1}{n})$
    \[U(f, P_n) \leq U(f, R_n) < \uint f + \frac{1}{n}\] 
    But, note that $f$ is integrable by assumption, which means 
    $\lint f = \uint f = \int_a^b f$. So,
    \[0 \leq U(f, P_n) - L(f, P_n) \leq \int_a^b f + \frac{1}{n} - (\int_a^b f - \frac{1}{n})\]
    \[= \frac{2}{n} \to 0 \text{ as } n \to \infty\]
    By The Comparison Lemma, $\underset{n\to\infty}{\lim}(U(f, P_n) - L(f, P_n)) = 0$. 
  \end{proof}
\end{theorem}

\begin{theorem}
  The \vocab{Archimedes-Riemann Theorem} left direction proof.

  \begin{proof}
    
  \hfill

  $\Longleftarrow$. Suppose $\underset{n\to\infty}{\lim} (U(f, P_n) - U(f, P_n)) = 0$
  for some sequence of partitions $P_n$. We want to show that $f$ is integrable, 
  which means showing $\lint f = \uint f$. But recall that 
  \[0 \leq \uint f - \lint f \leq U(f, P_n) - L(f, P_n)\]
  by the first consequence in the definition of integrable. By the Comparison Lemma, 
  \[\uint f - \lint f = 0 \implies \uint f = \lint f \implies \text{f is integrable}\]
  Moreover, 
  \[0 \leq U(f, P_n) - \uint f \leq U(f, P_n) - L(f, P_n) \text{ by (2)}\]
  \[\implies \lim_{n\to\infty} U(f, P_n) = \uint f = \int_a^b f\]
  Similarly, using (3), 
  \[\lim_{n\to\infty} L(f, P_n) = \lint f = \int_a^b\]
  \end{proof}
\end{theorem}

\begin{definition}
  $\{P_n\}$ is said to be an \vocab{Archimedian sequence of partitions (Asop)} for $f$
  on $[a,b]$ if
  \[\lim_{n\to\infty} (U(f, P_n) - L(f, P_n)) = 0\]
\end{definition}

\begin{example}
  Prove $f(x) = x$ is integrable over $[0, 1]$. 
  \begin{proof}
    Let $P_n$ be the $nth$ regular partition. $P_n$ is regular is 
    $x_i = a + i\frac{b-a}{n} = a + i\Delta x$. (This just means that each subinterval
    is the same length). 
    \[P_n = \{0, \frac{1}{n}, \frac{2}{n}, \ldots, 1\}\]
    Note that $m_i = \inf\{f(x) \ | \ x \in [x_{i-1}, x_i]\} \implies m_i = \inf\{f(x) \ | \ x \in [\frac{i-1}{n}, \frac{i}{n}]\} = f(\frac{i-1}{n}) = \frac{i-1}{n}$, 
    which is just the left endpoint of the subinterval. Simiarly, 
    $M_i = \frac{1}{n}$, the right endpoint of the interval. Therefore, 
    by definition of Darboux Upper and Lower Sums, 
    \[U(f, P_n) - L(f, P_n) = \sum_{i=1}^n M_i(x_{i-1} - x_i) - \sum_{i=1}^n m_i(x_{i-1}, x_i)\]
    \[= \sum_{i=1}^n (\frac{i}{n} * \frac{1}{n} - (\frac{i-1}{n} * \frac{1}{n}))=  \sum_{i=1}^n \frac{1}{n^2} = \frac{1}{n}\]
    and it is known that $\underset{n\to\infty}{\lim}\frac{1}{n} = 0$. Therefore, 
    \[\lim_{n\to\infty}(U(f, P_n) - L(f, P_n)) = 0\]
    Thus, $P_n$ is an Asop and using the Archimedian Theorem, $f(x) = x$ is integrable. We can find the 
    integral
    \[\int_0^1 f(x) dx = \int_0^1 x \ dx\]
    Using the "Moreover" part of the AR Theorem, 
    \[\int_0^1 x dx = \lim_{n\to\infty} U(f, P_n) = \lim_{n\to\infty}\sum_{i=1}^n \frac{i}{n} * \frac{1}{n}\]
    \[= \lim_{n\to\infty}\frac{1}{n^2}\sum_{i=1}^n i = \lim_{n\to\infty}\frac{1}{n^2}(\frac{n^2 + n}{2}) = \frac{1}{2}\]
  \end{proof}
\end{example}

\begin{theorem}
  Every monotone function $f: [a,b] \to \RR$ is integrable.
  \begin{proof}
    WLOG, suppose $f$ is monotone increasing. Let $P_n$ be a 
    regular partition. Since $f$ is monotone increasing, 
    \[m_i = f(x_{i-1}) \leq f(x) \leq f(x_i) = M_i, x \in [x_{i-1}, x_i]\]
    Then, 
    \[U(f, P_n) - L(f, P_n) = \sum_{i=1}^n (M_i - m_i) (x_i - x_{i-1})\]
    \[= \frac{b-a}{n}\sum_{i=1}^n (f(x_i) - f(x_{i-1}))\]
    Note that this is a telescope and so
    \[= \frac{b-a}{n}(f(x_n) - f(x_0)) = \frac{b-a}{n}(f(b) - f(a))\]
    Let $c = (b-a)(f(b) - f(a)) \in \RR$. Then 
    \[\lim_{n\to\infty}(U(f, P_n) - L(f, P_n)) = \lim_{n\to\infty}\frac{1}{n}(c) = 0\]
    Thus, $P_n$ is Asop and by the AR Theorem, $f$ is integrable.
  \end{proof}
\end{theorem}

\begin{theorem}
  Every step function $f: [a,b] \to \RR$ is integrable. 

  \begin{proof}[Sketch]
    For the partition points inside one region, $M_i = m_i$. 
    For the subintervals at the gaps/jumps, there are finitely many and 
    they can still be bounded using $M_i, m_i$. 
  \end{proof}
\end{theorem}

\subsection{Additivity, Monotonicity, Linearity}

\subsubsection{Additivity}

\begin{theorem}
  Suppose $f: [a,b] \to \RR$ is integrable and $c \in (a,b)$. Then 
  $f$ is integrable on $[a,c]$ and $[c,b]$ and $\int_a^b f = \int_a^c f + \int_c^b f$.

  \begin{proof}
    Since $f$ is integrable on $[a,b]$ by the AR Theorem, there exists 
    an Asop $\{P_n\}$ on $[a,b]$ for $f$. Let $Q_n = P_n \cup \{c\}$. We 
    WTS that $Q_n$ is Asop. By the Refinement Lemma, 
    \[L(f, P_n) \leq L(f, Q_n) \implies -L(f, P_n) \geq -L(f, Q_n)\]
    \[U(f, P_n) \geq U(f, Q_n)\]
    Therefore,
    \[0 \leq U(f, Q_n) - L(f, Q_n) \leq U(f, P_n) - L(f, P_n)\]

    Since $P_n$ is Asop, then $\underset{n\to\infty}{\lim}(U(f, P_n) - L(f, P_n)) = 0$
    and so by Comparison Lemma, $\underset{n\to\infty}{\lim}(U(f, Q_n) - L(f, Q_n)) = 0$
    and so $Q_n$ is an Asop for $f$ on $[a,b]$. Observe that
    \[Q_n = \{x_0, \ldots, x_k, c, x_{k+1}, \ldots, x_n\}\]
    Let $R_n = Q_n \cap [a,c]$ and let $S_n = Q_n \cap [c,b]$. Then, 
    \[U(f, R_n) = \sum_{i=1}^k M_i(x_i - x_{i-1}) + A(c-x_k), \ A = \sup\{f(x) \ | \ x\in[x_k, c]\}\]
    \[U(f, S_n) = B(x_{k+1} - c) + \sum_{i=k+1}^n M_i(x_i - x_{i-1}), B = \sup\{f(x) \:|\: x \in [c, x_{k+1}]\}\]
    And so $U(f, Q_n) = U(f, R_n) + U(f, S_n)$ and similarly $L(f, Q_n) = L(f, R_n) + L(f, S_n)$.
    \[0 \leq U(f, R_n) - L(f, R_n) \leq U(f, Q_n) - L(f, Q_n)\]
    By CL, $\lim_{n\to\infty}(U(f, R_n) - L(f, R_n)) = 0$
    and so $f$ is integrable on $[a,b]$ and similarly for $[c,b]$. 
    and
    \[\int_a^b f= \int_a^c f+ \int_c^b f\]
  \end{proof}
\end{theorem}

\subsubsection{Monotonicity}

\begin{proof}

\hfill

\begin{theorem}
  If $f, g: [a,b] \to \RR$ are bounded with $f(x) \leq g(x) \ \forall \ x \in [a,b]$, 
  then 
  \[(1) \ \ \lint f \leq \lint g \text{ and } \uint f \leq \uint g\]
  and if $f, g$ are integrable, then
  \[(2) \ \ \int_a^b f \leq \int_a^b g\]
  \begin{proof}[Sketch]
      Sine $f, g$ are integrable, use AR Theorem and Refinement Lemma such that 
      $\exists \ \{P_n\}$ on $[a,b]$ such that 
      \begin{align*}
        \lim_{n\to\infty} U(f, P_n) = \int_a^b f && \lim_{n\to\infty} U(g, P_n) = \int_a^b g
      \end{align*}
      Since $f(x) \leq g(x) \ \forall \ x \in [a,b]$ then 
      $U(f, P_n) \leq U(f, P_n)$ by using sup. So
      \[\int_a^b f = \underset{n\to\infty}{\lim}U(f, P_n) \leq \lim_{n\to\infty}U(g, P_n) = \int_a^b g \implies \int_a^b f \leq \int_a^b g\]
      as desired.
  \end{proof}
\end{theorem}

\end{proof}

\subsubsection{Linearity}

\begin{theorem}
  
Suppose $f, g: [a,b]\to\RR$ are both integrable. Let $\alpha, \beta \in \RR$. 
Then $(\alpha f + \beta g): [a,b] \to \RR$ is integrable. and 
\[\int_a^b (\alpha f + \beta g) = \alpha \int_a^b f + \beta\int_a^b g\]
\begin{proof}

\hfill
  
Let us first show that scalar multiplication is satisfied. Let $P = \{x_0, \ldots, x_n\}$ be a partition on $[a,b]$ and define 
$M_i(f), M_i(g), m_i(f), m_i(g)$ as usual. 

If $\alpha \geq 0, \alpha \in \RR$
\begin{align*}
  M_i(\alpha f) = \alpha M_i(f) && 
  m_i(\alpha f) = \alpha m_i(f)
\end{align*}
by exercising the definition of sup, inf.

If $\alpha < 0, \alpha \in \RR$
\begin{align*}
  M_i(\alpha f) = \alpha m_i(f) && 
  m_i(\alpha f) = \alpha M_i(f)
\end{align*}

Let $\alpha \geq 0$. Then 
\[U(\alpha f, P) - L(\alpha f, P) = \sum_{i=1}^n (M_i(\alpha f) - m_i(\alpha f))(x_i - x_{i-1})\]
\[= \alpha \sum_{i=1}^n (M_i(f) - m_i(f))(x_i - x_{i-1})\]
\[= \alpha (U(f, P) - L(f, P))\]
Suppose $P_n$ is an ASOP for $f$ on $[a,b]$, since $f$ is integrable take the limit.
\[\lim_{n\to\infty}(U(\alpha f, P_n) - L(\alpha f, P_n)) = \alpha \lim_{n\to\infty}(U(f, P_n) - L(f, P_n)) = 0\]
and so therefore, $P_n$ is ASOP for $\alpha f$ and $\alpha f$ is integrable.

If $\alpha < 0$ then it's similar.

\end{proof}

\end{theorem}

\begin{theorem}

Now we will show the second half of the proof, the additivity part.

\begin{proof}

\hfill

Now for the second part, we WTS that $\int_a^b(f + g) = \int_a^b + \int_a^b g$. Consider 
\[(f+g)(x_i) = f(x_i) + g(x_i) \leq M_i(f) + M_i(g) \ \forall \ x \in [x_{i-1}, x_i]\]
Starting with 
\[M_i(f + g) \leq M_i(f) + M_i(g)\]
Multply by $(x_i - x_{i-1})$ and add all of the subintervals and similarly for Darboux Lower Sums to obtain 
\begin{align*}
U(f + g, P) \leq U(f, P) + U(g, P) && L(f + g, P) \geq L(f, P) + L(g, P)
\end{align*}
Take $\{P_n\}$ ASOP for $f$ on $[a,b]$ since $f, g$ are integrable by the AR Theorem. 
Similarly take $\{R_n\}$ ASOP for $g$ on $[a,b]$. Let $Q_n = P_n \cup R_n$ (refinement).
Now we want to show that $Q_n$ is an ASOP for both $f$ and $g$ individually. Then 
\[ 0\leq U(f + g, Q_n) - L(f + g, Q_n)\]
\[\leq U(f, Q_n) + U(g, Q_n) - \left( L(f, Q_n) - L(g, Q_n)\right)\]
\[= U(f, Q_n) - L(f, Q_n) + U(g, Q_n) - L(g, Q_n)\]
By CL, $\underset{n\to\infty}{\lim}\left(U(f + g, Q_n) - L(f + g, Q_n)\right) = 0 \implies f + g$
is integrable and so 
\[\int_a^b f + g = \underset{n\to\infty}{\lim}U(f + g, Q_n) \leq \lim_{n\to\infty} (U(f, Q_n) + U(g, Q_n)) = \int_a^b f + \int_a^b g\]
But at the same time 
\[\int_a^b f + g = \lim_{n\to\infty} L(f + g, Q_n) \geq \leq \lim_{n\to\infty} (L(f, Q_n) + L(g, Q_n)) = \int_a^b f + \int_a^b g\]
which implies that $\int_a^b f + g = \int_a^b f + \int_a^b g$ and combining the result from the first part of the proof 
we obtain $\int_a^b \alpha f + \beta g = \alpha \int_a^b f + \beta \int_a^b g$, as desired. 
\end{proof}
\end{theorem}

\begin{corollary}
  Suppose $f: [a,b] \to \RR, |f|: [a,b] \to \RR$ are integrable.
  Then
  \[|\int_a^b f| \leq \int_a^b |f|\]
  \begin{proof}[Sketch]
    $\forall \ x \in [a,b]$
    \[- |f(x)| \leq f(x) \leq |f(x)|\]
    Applying montonicity and linearity, 
    \[-\int_a^b |f(x)| \leq \int_a^b f(x) \leq \int_a^b |f(x)|\]
    which is $|\int_a^b f| \leq \int_a^b |f|$
  \end{proof}
\end{corollary}

\subsection{Continuity and Integrability}

So far we have only proven the following functions are integrable: $x, x^2$ 
and monotone functions. 

\begin{lemma}
  Let $f: [a,b]\to\RR$ be continuous and $P$ partition on $[a,b]$. Then $\exists$ a partition interval of $P$ that contains two points $u, v$ with
  \[0 \leq U(f, P) - L(f, P) \leq (f(u) - f(v))(b-a)\] 

  \begin{proof}[Sketch]
  
  \hfill

  Let $P = \{x_0, \ldots, x_n\}$ be a partition of $[a,b]$. 
  \begin{itemize}
    \item $f$ is continuous on $[a,b]$ so $f$ is continuous on all $[x_{i-1}, x_i] \ \forall \ i$
    \item By EVT, max and min are attained (stronger than inf and sup)
    \item Define the min and the max, $f(u_i) = m_i, f(v_i) = M_i$
    \item Choose $i_0$ such that $M_{i_0} - m_{i_0} := \underset{1 \leq i \leq n}{\max}(M_i - m_i)$. Intuitively, 
    this means to choose the largest difference betwen subinterval max - min. 
    \item Let $u := u_{i_0}$, $v := v_{i_0}$. 
    \item Then $M_i - m_i \leq M_{i_0} - m_{i_0} = f(v) - f(u)$ by definition of max.
    \item Then $0 \leq U(f, P) - L(f, P) = \sum_{i=1}^n (M_i - m_i)(x_i - x_{i-1})$
    \[\leq \sum_{i=1}^n (f(v) - f(u))(x_i - x_{i-1}) = (f(v) - f(u))(b-a)\]
    So we have found $u, v \in [a,b]$ with 
    \[ 0 \leq U - L \leq (f(v) - f(u))(b-a)\]
  \end{itemize}

  \end{proof}
\end{lemma}

\begin{remark}
  Recall that continuity on $[a,b]$ implies uniform continuity. 
  For any $\{u_n\}$ and $\{v_n\}$ in $D$ if $\underset{n\to\infty}{\lim}(u_n - v_n) = 0 \implies \underset{n\to\infty}{\lim}(f(u_n) - f(v_n)) = 0$.
  Use the Lemma above for a sequence of partitions and sequence of points
  $\{u_n\}$ and $\{v_n\}$ to prove that if $f$ is continuous on $[a,b]$ then $f$ is integrable.

\end{remark}

\begin{theorem}
  A continuous function $f: [a,b] \to \RR$ is integrable.

  \begin{proof}
    
    \hfill

  Let $\{P_n\}$ be a sequence of regular partitions. For each $n$, apply the previous lemma: \[(*) \ \ \ 0 \leq U(f, P_n) - L(f, P_n) \leq (f(v_n) - f(u_n))(b-a)\]
  Note that $|u_n - v_n| \leq \frac{b-a}{n}$ since $u_n, v_n \in [x_{i-1}, x_i]$.
  Take the limit as $n\to\infty$, by CL $\underset{n\to\infty}{\lim}(u_n - v_n) = 0$ since 
  $\underset{n\to\infty}{\lim}\frac{b-a}{n} = 0$.

  Since $f$ is continuous on $[a,b]$, $f$ is uniformly continuous on $[a,b]$ 
  \[\underset{n\to\infty}{\lim}(f(u_n) - f(v_n)) = 0 \ \ \ (1)\]
  Take $(*)$ and apply a limit 
  \[0 \leq \lim_{n\to\infty}(U(f, P_n) - L(f, P_n)) \leq \lim_{n\to\infty}(f(v_n) - f(u_n))(b-a)\]
  By CL, $\underset{n\to\infty}{\lim}(U(f, P_n) - L(f, P_n)) = 0$ and so by AR Theorem, 
  $f$ is integrable.
  \end{proof}
\end{theorem}

\begin{theorem}
  Suppose $f: [a,b] \to \RR$ is bounded and continuous on $(a,b)$. Then 
  $f: [a,b]\to\RR$ is integrable and the value of the integral $\int_a^b f$ does not 
  depend on the values of $f$ at the endpoints.

  \begin{proof}[Sketch]
    Look at the endpoints $a, b$ and take $a_n \to a, b_n \to b$ and measure how 
    big the finite (because bounded) gap of the discontinuity is. Bound the difference of the gap and take 
    $n\to\infty$ for $P_n$.
    \[U(f, P_n) - L(f, P_n) \leq \text{usual } + \text{bound}(a_n-a) + \text{bound}(b_n - b)\]
    Note that $f$ does not need continuity at the endponts to be integrable.
  \end{proof}
\end{theorem}

\begin{example}
  Consider
  \[f(x) = \begin{cases}
    \sin(\frac{1}{x}) \text{ if } 0 < x \leq 1\\
    100 \text{  if } x = 0
  \end{cases}\]
  $f(x): [0,1] \to \RR$ is bounded since $|f(x)| \leq 100$ and $f: (0,1) \to\RR$ is continuous. So $f$ is 
  integrable by the previous theorem.
\end{example}

\subsection{The First Fundamental Theoreom of Calculus (FTC1)}

\begin{theorem}

  Let $F: [a,b] \to \RR$ be continuous on $[a,b]$ and differnetiable on $(a,b)$ and $F': (a,b) \to \RR$
  is continuous and bounded, then 
  \[\int_a^b F'(x) dx = F(b) - F(a)\]

  \begin{proof}
    Assume $F': (a,b) \to \RR$ is continuous and bounded, then $F': [a,b] \to \RR$ is integrable 
    (above, 6.4) since the integral does not depend on endpoints. Let $P$ be a partition of $[a,b]$. 
    Then 
    \[U(F', P) = \sum_{i=1}^n M_i(F')(x_i - x_{i-1})\]
    Consider $[x_i, x_{i-1}]$, since $F$ is continuous on $[a,b]$, differentiable on $(a,b)$, we can 
    apply MVT to the partition interval, $\exists \ c_i \in [x_i, x_{i-1}]$, with 
    \[F'(c_i) = \frac{F(x_i) - F(x_{i-1})}{x_i - x_{i-1}} \ \forall \ i, 1 \leq i \leq n\]
    Then use sup to get 
    \[\frac{F(x_i) - F(x_{i-1})}{x_i - x_{i-1}} = F'(c_i) \leq M_i(F')\]
    by the definition of sup. Then multiply by $(x_i - x_{i-1})$ to get 
    \[\sum_{i=1}^n (F(x_i) - F(x_{i-1})) \leq \sum_{i=1}^n M_i(F')(x_i - x_{i-1}) = U(F', P)\]
    Note that the left side is telescoping, and so we obtain that 
    \[F(b) - F(a) \leq U(F', P)\]
    By property of inf in Upper Integral
    \[F(b) = F(a) \leq \int_a^{\bar{b}} F' = \int_a^b F'\]
    because $F'$ is integral. 
    Simiarly, it can be shown that $F(b) - F(a) \geq \int_a^b F'$ which implies that 
    $F(b) - F(a) = \int_a^b F'$.
  \end{proof}
\end{theorem}

\begin{note}
  Notation: $f: [a,b] \to \mathbb{R}$ is continous and bounded on $(a,b)$, then 
  FTC1 asserts if it possible to find an antiderivative $F: [a,b] \to \RR$ for $f$
  then the integral is given by
  \[\int_a^b f(x) dx = F(b) - F(a)\]
  An antiderivatve continuous function $F$ having a derivative on $(a,b)$ such that 
  \[F'(x) = f(x) \ \forall \ (a,b)\]
  Note that FTC1 only gives us some (most) integrals. In order to 
\end{note}

\subsection{FTC2 and Differentiating Integrals}

\begin{theorem}
  The \vocab{Mean Value Theorem for Integrals} states that suppose $f: [a,b] \to \RR$ is continuous. 
  Then $\exists \ x_0 \in (a,b)$ at which 
  \[f(x_0) = \frac{1}{b-a}\int_a^b f(x) dx\]

  \begin{proof}
    Use EVT on $f: [a,b] \to \RR$ (cont). Therefore, $\exists \ x_m, x_M \in [a,b]$ with 
    \[f(x_m) \leq f(x) \leq f(x_M) \ \forall \ x \in [a,b]\]
    By monotonicity of $\int$: 
    \[\int_a^b f(x_m) \leq \int_a^b f(x) \leq \int_a^b f(x_M)\]
    \[f(x_m) \int_a^b 1 \leq \int_a^b f(x) \leq f(x_M) \int_a^b 1\]
    \[f(x_m) (b-a) \leq \int_a^b f(x) \leq f(x_M) (b-a)\]
    \[f(x_m) \leq \frac{1}{b-a}\int_a^b f(x) \leq f(x_M)\]
    From here, apply the IVT, $\exists \ x_0 \in (x_m, X_M)$ such that 
    \[\exists x_0 \in (a,b) \text{ s.t. } f(x_0) = \frac{1}{b-a}\int_a^b f\]
  \end{proof}
\end{theorem}

\begin{definition}
  Consider the \vocab{area function}
  \[f(x) = \int_a^x f(t) dt\]
  Input changes the upper bound. Lower bound is fixed. Tells you how much area is under $f(t)$ between 
  $a$ and $x$.
\end{definition}

\begin{proposition}
  Suppose $f: [a,b] \to \RR$ is integrable. (This could be discontinuous). Define $F(x) = \int_a^x f(t) dt \ \forall \ x \in [a,b]$. 
  Then $F: [a,b] \to \RR$ is continuous. 

  \begin{proof}
    
    \hfill

    Let $u, v \in [a,b]$ with $u < v$ WLOG. Let $F(v) = \int_a^v f = \int_a^u f + \int_u^v f = F(u) + \int_u^v f$ by additivty.  Therefore, \[F(v) - F(u) = \int_u^v = f \ \ \ (*)\]
    Since $f$ is integrable and bounded, choose $M > 0$, 
    \[-M \leq f(x) \leq M \ \forall \ x \in [a,b]\]
    \[-M \leq f(x) \leq M \ \text{ if } u \leq x \leq v\]
    By monotone integral theorem, 
    \[-\int_u^v M \leq \int_u^v f \leq \int_u^v M\]
    \[-M(v-u) \leq \int_u^v f \leq M(v-u)\]
    \[|F(v) - F(u)| \leq M|v-u| \ \forall \ u, v \in [a,b]\]
    Recall this from Homework 4, if Lipschitz continuous, then it is also uniform continuous.
    $F: [a,b] \to \RR$ is uniformly continuous, which implies continuous, and so we are done.
  \end{proof}
\end{proposition}

\begin{remark}
  The above proof is more broad than the FTC2, shown below.
\end{remark}

\begin{theorem}
  The \vocab{Fundamental Theorem of Calculus 2} states that 
  suppose $f: [a,b] \to \RR$ is continuous. Then, 
  \[\frac{d}{dx} \Biggl(\int_a^x f(t) dt\Biggr) = f(x) \ \forall \ x \in (a,b)\]


  \begin{proof}

    \hfill

    Note that $\int_a^b f = -\int_b^a f$. Define $F(x) = \int_a^x \ \forall \ x \in [a,b]$. 
    $F$ is continuous from the proposition above. Let $x_o \in (a,b)$. 

    We WTS that
    \[F'(x_0) = \lim_{x\to x_0}\frac{F(x) - F(x_0)}{x - x_0}\]
    Let $x \in (a,b)$ with $x \neq x_0$.

    Case 1: If $x > x_0$. Then 
    \[F(x) - F(x_0) = \int_{x_0}^x f \implies \int_a^x f - \int_a^{x_0} f = -\int_x^a f - \int_a^{x_0} f\]
    \[= -(\int_x^a f + \int_a^{x_0} f) \implies -\int_x^{x_0} f = \int_{x_0}^x f\]
    Case 2: If $x < x_0$, then 
    \[F(x) - F(x_0) = \int_{x_0}^x f = \int_a^x f - \int_a^{x_0} f = -\int_x^a f - \int_a^{x_0} f\]
    \[- (\int_x^a f + \int_a^{x_0} f) = -\int_x^{x_0}f = \int_{x_0}^x f\]
    In both cases, apply MVT for $\int$
    \[\exists \ c \in (a,b) \text{ s.t. } f(c(x)) = \frac{1}{x-x_0}\int_{x_0}^x f\]
    Rearranging and using what we have above,
    \[= \frac{F(x) - F(x_0)}{x - x_0}\]
    Applying the limit as $x\to x_0$,
    \[\lim_{x\to x_0}\frac{F(x) - F(x_0)}{x - x_0} = \lim_{x\to x_0} f(c(x)) = F'(x_0)\]
    by definition of derivative. Since $f$ is continuous at $x_0$, then $\underset{x\to x_0}{\lim} {f(c(x))} = f(x_0)$
    as desired.
  \end{proof}
\end{theorem}

\begin{corollary}
  Some corollary results from FTC2. 

  \begin{enumerate}
    \item $f: [a,b] \to\RR$ is continuous then $\frac{d}{dx} \int_a^x f= \frac{d}{dx}(-\int_a^x f) = -f(x)$
    \item $I, J$ open intervals, $h(I) \subseteq J$. Then,
    \begin{align*}
      f: I \to \mathbb{R} \text{cont} && h: J \to \mathbb{R} \text{ diff }
    \end{align*}
    Fix $a$: then $\frac{d}{dx}\int_a^{h(x)} = f(h(x)) * h'(x)$ using the chain rule

    \[\int_{x^2}^{-3} \cos(1-5t)dt = F(x) \implies F'(x) = -ex^{2x^2}\cos(1-5x^2) * 2x\]
  \end{enumerate}
\end{corollary}

\section{Integration Techniques}

Skip this section.

\section{Approximation by Taylor Polynomials}

\subsection{Taylor Polynomials}

\begin{note}
  Note that $(e^x)^1 = e^x$.
\end{note}

\begin{definition}
  Let $I$ be a neighborhood of $x_0$, and so we say $f: I \to \RR$ and $g: I \to \RR$
  are said to have \vocab{contact of order $0$ at $x_0$} if $f(x_0) = g(x_0)$. 
  \[\vdots\]
  They are said to have \vocab{contact of order $n$ at $x_0$} oif $f^{(k)}(x_0) = g^{(k)}(x_0) \ \forall \ k \in [0, n]$.
\end{definition}

\begin{note}
  Note that in this chapter, $0 \in \NN$ because for the above definition, it means just the functional values.
\end{note}

\begin{theorem}
  Let $I$ be a neighborhood of $x_0$. Suppose $f: I \to \RR$ has $n$ derivatives, $n \in \NN$. 
  Then there is a unique polynomial of degree at most $n$ that has contact of order $n$ with 
  $f$ at $x_0$. The polynomial is defined as 
  \[P_{n}(x) = f(x_0) + \frac{f'(x_0)}{1!}(x - x_0) + \cdots + \frac{f^{(n)}(x_0)}{n!}(x - x_0)^n\]

  \begin{proof}
    
  \hfill

  Suppose $P_n(x)$ is a general polynomial.
  \[P_n = a_0 + a_1(x - x_0) + a_2(x - x_0)^2 + a_3(x-x_0)^3 + \cdots + a_n(x - x_0)^n\]
  $P_n(x)$ has degree $n$. Now let us work to get contact of order at least $n$ with $f$ at $x=x_0$.
  \[n = 0 \implies P_0(x) = a_0 \implies p(x_0) = a_0\]
  Since we want contact of order $0$ with $f$ at $x_0$, then 
  \[f(x_0) = p(x_0) = a_0 \implies f(x_0) = a_0\]
  \[n = 1 \implies P_n'(x_0) = a_1 + 2a_2(x-x_0) + 3a_3(x-x_0)^2 + \cdots + na_n(x-x_0)^{n-1}\]
  \[\implies P_n'(x_0) = a_1 = f'(x_0) \text{ in order to have contact of order 1}\]
  \[n = 2 \implies P_n''(x) = 2a_2 + 6a_3(x-x_0) + \cdots + n(n-1)a_n x^{n-2}\]
  Now plugging in $x=x_0$, we get
  \[\implies P_n''(x) = 2a_2 = f''(x_0) \implies a_2 = \frac{f''(x_0)}{2!}\]
  and we start to see the pattern.
  \[a_3 = \frac{f^{(3)}(x_0)}{3!}\]
  \[\text{Pattern: } a_k = \frac{f^{(k)}(x_0)}{k!}\]
  So putting coefficients $a_k$ into $P_n(x)$:
  \[P_n(x) = \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]
  \end{proof}
\end{theorem}

\begin{note}
  Note that this was only created for a single point $x_0$. The construction says nothing about 
  how the polynomial behaves away from $x_0$. 
\end{note}

\begin{example}
  Find the nth Taylor Polynomial for $f(x) = e^x$ at $x=0$
  \[P_n(x) = \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]

  \begin{proof}[Solution]
    Note that $f^{(k)}(0) = 1 \ \forall \ k$. Thus, 
    \[P_n(x) = \sum_{i=0}^n \frac{1}{k!}(x-0)^k = \sum_{i=0}^n \frac{x^k}{k!}\]
  \end{proof}
\end{example}

\subsection{Lagrange Remainder (Error) Theorem}

How close is $P_n(x)$ to $f(x)$? What is the error?

\begin{definition}
  Define $R_n := f(x) - P_n(x)$ where $R_n: I \to \RR$ is the \vocab{nth remainder}
\end{definition}

\begin{note}
  Recall this Corollary from Cauchy MVT in Chapter 4. 
  Suppose $f: I \to \RR$ has $n$ derivatives for $f^{(k)}(x_0) = 0 \ \forall \ k, 0 \leq k \leq n-1$. 
  Then $\ \forall \ x \neq x_0, \ \exists z \in (x, x_0)$ with 
  \[f(x) = \frac{f^{(n)}(z)}{n!}(x-x_0)^n\]
\end{note}

\begin{theorem}
  Let $I$ be a neighborhood of $x_0$, and let $\NN$ include $0$. 
  Suppose $f: I \to \RR$ has $n + 1$ derivatives. Then for each point $x \neq x_0$ in $I$, $\exists \ c \in (x, x_0)$
  \[f(x) = \sum_{k=1}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k + \frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}\]
  where the summation is the Taylor polynomial and the second term is the $R_n(x)$ remainder.

  \begin{proof}
    Let $P_n(x)$ be the nth Taylor Polynomial for $f(x)$ at $x_0$. 
    \[P_n(x) = \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]
    Define $R_n(x) := f(x) - P_n(x) \ \forall \ x \in I$. By construction in 8.1, 
    $f(x)$ and $p_n(x)$ have a contact of order $n$ at $x_0$
    so $R_n^{(k)} = 0 \ \forall \ k \in [0, n]$. Thus, we can apply the Corollary from the CMVT on $R$:
    \[\ \forall \ x \neq x_0, \ \exists \ c \text{ between } x_0, x \text{ w/ } R_n(x) = \frac{R^{(n+1)(c)}}{(n+1)!}(x-x_0)^{n+1}\]
    But $R^{(n+1)}(c) = f^{(n+1)}(c) - P_n^{(n+1)}(c)$ by definition of $R$. 
    Note that the second term is the Polynomial degree $n$ so $(n+1)$th derivative is $0$.
    \[R^{(n+1)}(c) = f^{(n+1)}(c) - 0\]
    By substitution into the corollary from CMVT, 
    \[R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}\]
    where $R_n := f - P_n \implies f = P_n + R_n$
    \[f(x) = \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k + \frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}\]
  \end{proof}
\end{theorem}

\subsection{Convergence of Taylor Polynomials (n to infinity)}

\begin{definition}
  $\{S_n\}$ is a \vocab{sequence of partial sums} when $S_n = \sum_{k=0}^n a_k$ for a given $a_k$. 
  \[\sum_{k=0}^\infty a_k = \lim_{n\to\infty} = \lim_{n\to\infty} \sum_{k=0}^n a_k \text{ if } \{s_n\} \text{ converges}\]
  Note that if $\{S_n\}$ does not converge, then $\sum_{k=0}^\infty a_k$ diverges. 
\end{definition}

\begin{definition}
  Let $P_n(x)$ be the nth Taylor Polynomial for $f: I \to \RR$ then 
  \[\lim_{n\to\infty}P_n(x) = f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\]
  is called the \vocab{Taylor Series Expansion of $f$ at $x_0$}
\end{definition}

\begin{note}
  Note that we can assume that $\underset{n\to\infty}{\lim}r^n = 0$ if $|r| < 1$.
\end{note}

\begin{lemma}
  $\underset{n\to\infty}{\lim}\frac{c^n}{n!} = 0, c \in \RR$

  \begin{proof}
    Let $c \in \RR$ be a constant and choose $k \in \NN$ such that $k \geq 2|c| \implies |c| \leq \frac{k}{2}$, which is doable by AP.  Apply absolute value for $n \geq K$, \[0 \leq |\frac{c^n}{n!}| = \frac{|c||c| \cdots |c|}{(1)(2) \cdots (n-1)(n)}\] 
    \[= \left[ \frac{|c||c|\cdots|c|}{1 * 2 * \cdots * k} \right] \left[ \frac{|c|\cdots|c|}{(k+1)\cdots n}\right] = \frac{|c|^k}{k!}\frac{|c|^{n-k}}{(k+1)\cdots n} \leq \frac{|c|^k}{k!}\frac{|c|^{n-k}}{k^{n-k}}\]
    \[\leq \frac{|c|^k}{k!}\frac{(k/2)^{n-k}}{k^{n-k}} = \frac{|c|^k}{k! 2^{n-k}} \leq |c|^k (\frac{1}{2})^{n-k}\]
    \[= |c|^k \frac{(1/2)^n}{(1/2)^k} = |c|^k * 2^k * (\frac{1}{2})^n\]
    Note that $|c|^k * 2^k$ is a constant wrt $n$ and $(\frac{1}{2})^n \to \infty, n \to \infty$
    \[\lim_{n\to\infty}(\frac{1}{2})^n = 0\] and so since that term is a constant
    then by CL, $\underset{n\to\infty}{\lim}\frac{c^n}{n!} = 0$.
  \end{proof}
\end{lemma}

\begin{theorem}
  Let $I$ be a neighborhood of $x_0$ and $f: I \to \RR$ have derivative of all orders.  Suppose $r, M \in \RR^+$ such that $[x_0 -r, x_0 + r] \subseteq I$ and $\ \forall \ n$ with $x \in [x_0 - r, x_0 + r]$, 
  $|f^{(n)} (x)| \leq M^n$ then 
  \[f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k \text{ if } |x-x_0| \leq r\]

  \begin{proof}
    Let $P_n(x)$ be the nth Taylor Polynomial of $f$ at $x_0$. We WTS that
    \[f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k \leftrightarrow \lim_{n\to\infty}P_n \leftrightarrow \lim_{n\to\infty}(f(x) - P_n(x)) \leftrightarrow \lim_{n\to\infty}R_n(x)\]
    \[ = 0 \leftrightarrow \lim_{n\to\infty}\frac{f^{(n+1)}(z)}{(n+1)!}(x-x_0)^{n+1}\]
    by the Lagrange Remainder Theorem, $z$ is strictly between $x$ and $x_0$. 
    By assumption, $|f^{(n+1)}| \leq M^{n+1}$ and from the given 
    $|x-x_0| \leq r$
    \[\left| \frac{f^{(n+1)}(z)}{(n+1)!}(x-x_0)^{n+1} \right| \leq \left| \frac{M^{n+1}r^{n+1}}{(n+1)!}\right| = \left| \frac{(Mr)^{n+1}}{(n+1)!} \right|\]
    Note that $\underset{n\to\infty}{\lim}\left|\frac{(Mr)^{n+1}}{(n+1)!}\right| = 0$ and so by CL
    \[\lim_{n\to\infty}\frac{f^{(n+1)}(z)}{(n+1)!}(x-x_0)^{n+1} = \lim_{n\to\infty}R_n(x) = 0 \implies \]
    the Taylor Series expension of $f$ at $x_0$ converges to $f(x)$
  \end{proof}
\end{theorem}

\subsection{Skip (Thanks Eileen)}

\subsection{Cauchy Integral Remainder Theorem}

Previously, $f(x) = P_n(x) + R_n(x)$, where the $R_n(x)$ was the formula using the Lagrange Remainder using unknown $c, z$. 
Now, we will use $R_n(x)$ as an integral and approximate it using sums.

\begin{theorem}
  \vocab{Integration by Parts}: Suppose $f, g: [a,b] \to \RR$
  are continuous and have continuous bounded derivatives on $(a,b)$. Then 
  \[\int_a^b fg' = fg|_a^b - \int_a^b f'g\]
  \[u dv = uv - \int vdu\]
  \begin{proof}
    From product rule, 
    \[(fg)' = f'g + fg' \implies fg' = (fg') - f'g\]
    \[\int_a^b fg' = \int_a^b (fg)' - \int_a^b f'g\]
    Now by FTC1
    \[\int_a^b fg' = (fg)|_a^b - \int_a^b f'g\]
  \end{proof}
\end{theorem}

\begin{theorem}
  \vocab{Cauchy Integral Remainder Theorem}: Let $I$ be a neighborhood of $x_0 \in \RR$, and 
  let $n \in \NN \cup \{0\}$. Suppose $f: I \to \RR$ has $n + 1$ derivatives and that 
  $f^{(n+1)}: I \to \RR$ is continuous. Then for each $x \in I$
  \[f(x) = \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k + \frac{1}{n!}\int_{x_0}^x f^{(n+1)}(t)(x-t)^n dt\]
  where the first term is the nth Taylor Polynomial and the second term is the \vocab{Cauchy Integral Remainder}.

  \begin{proof}
    Basis step: $n=0$
    \[f(x_0) + \frac{1}{0!}\int_{x_0}^x f'(t)(x-t)^0 dt = f(x_0) + \int_{x_0}^x f'(t) dt = f(x_0) + f(x) - f(x_0) = f(x)\]
    Now for $n=1$ by FTC1: $\int_{x_0}^x f'(t) dt = f(x) - f(x_0) \implies f(x) = f(x_0) + \int_{x_0}^x f'(t) dt$
    and 
    \[\int_{x_0}^x f'(t) dt = \int_{x_0}^x -f'(t) \frac{d}{dt}(x-t) dt\]
    Let $u = -f'(t)$ and let $du = \frac{d}{dt}(x-t) \implies u = (x-t)$
    and so by Integration by Parts 
    \[= -f'(t) (x-t)\Bigg|_{t=x_0}^{t=x} - \int_{x_0}^x -f''(t) (x-t) dt = \]
    \[= -f'(x)(x-x) - (-f'(x_0)(x-x_0)) + \int_{x_0}^x f''(t) (x-t) dt\]
    Plugging this in for $\int_{x_0}^x f'(t) dt$
    \[f(x) = f(x_0) + f'(x_0)(x-x_0) + \frac{1}{1!}\int_{x_0}^x f''(t) (x-t) dt\]
    Note that the first two terms are terms of $P_n(x)$ and the last term is $R_1(x)$
    
    Inductive hypothesis: $f(x) = P_n(x) + \frac{1}{n!}\int_{x_0}^x f^{(n+1)}(t) (x-t)^n dt$

    Inductive step: Observe that 
    \[\frac{1}{n!}\int_{x_0}^x f^{(n+1)}(t) (x-t)^n dt = \frac{1}{n} \int_{x_0}^x f^{(n+1)}(t) \left[ \frac{d}{dt} -\frac{1}{n+1}(x-t)^{n+1}\right] dt\]
    \[= -\frac{1}{(n+1)!}\int_{x_0}^x f^{(n+1)}(t) \frac{d}{dt}(x-t)^{n+1} dt\]
    and using IBP, let $u = f^{(n+1)}(t)$ and $g' = \frac{d}{dt}(x-t)^{n+1} \implies g = (x-t)^{n+1}$
    \[= (-\frac{1}{(n+1)!}) f^{(n+1)}(t) (x-t)^{n+1}\Bigg|_{x_0}^x - \int_{x_0}^x f^{(n+2)} (x-t) dt\]
    \[\frac{f^{(n+1)}(x_0)}{(n+1)!}(x-x_0)^{n+1} + \frac{1}{(n+1)!}\int_{x_0}^x f^{(n+2)}(x-t) dt \implies P_{n+1}(x) + R_{n+1}(x)\]
  \end{proof}
\end{theorem}

\subsection{Skip 8.6}

\subsection{The Weierstrass Approximation Theorem}

\begin{theorem}
  \vocab{Weierstrass Approximation Theorem} states that suppose $f: [a,b] \to \RR$ is continous. Then for all $\epsilon > 0$, 
  there is a polynomial $p: \RR \to \RR$ such that $\ \forall \ x \in [a,b]$, we have 
  \[|f(x) - p(x)| < \epsilon\]
  Note that $p(x)$ may not be a Taylor Polynomial. This works for all $x$, 
  not just a small neighborhood around $x_0$. 
  \begin{proof}
    Omitted. Not expected to know for the exam.
  \end{proof}
\end{theorem}

\section{Sequences and Series of Functions}

\subsection{Sequences and Series of Numbers}

\begin{note}
  Note that previously a sequence of numbers is convergent if 
  \[\ \forall \ \epsilon > 0, \ \exists N \in \NN \text{ s.t. } \ \forall n \geq N, |a_n - a| < \epsilon\]
  However, we needed to know the limit $a$ beforehand in order to use the definition.
  Some tools we have to determine convergence 
  \begin{enumerate}
    \item Monotone Convergence Theorem: bounded monotone sequence $\implies$ converge
  \end{enumerate}
\end{note}

\begin{definition}
  A sqeuence $\{a_n\}$ is called a \vocab{Cauchy Sequence} if 
  \[\forall \ \epsilon > 0, \ \exists \ N \in \NN \text{ s.t. } n, m \in \NN \implies |a_n - a_m| < \epsilon\]
  Essentially, the terms of the sqeuence get closer to each other after $N$ and we do not need to know $\underset{n\to\infty}{\lim}a_n = a$.
\end{definition}

\begin{theorem}
  If a sequence converges, then it is a Cauchy Sequence. 

  \begin{proof}
    Let $\epsilon > 0$. Then $\ \exists \ N \in \NN$ such that $\forall \ n \in \NN, |a_n - a| < \frac{\epsilon}{2}$
    by definition of convergent sequence, since it works for all $\epsilon$. Thus if $n, m \in \NN$, we have 
    \[|a_n - a_m| = |a_n - a + a - a_m| \leq |a_n - a| + |a - a_m| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]
  \end{proof}
\end{theorem}

\begin{lemma}
  If $\{a_n\}$ is Cauchy, then $\{a_n\}$ is bounded. 

  \begin{proof}
    Since $\{a_n\}$ is Cauchy, $\ \forall \ \epsilon > 0, \ \exists \ N \in \NN$ such that 
    $\forall \ m, n \geq NN, |a_n - a_m| < \epsilon$. Let $\epsilon = 1$. So 
    \[|a_n - a_m| < 1 \ \forall \ m, n \in N\]
    In particular, $|a_n - a_N| < 1 \ \forall \ n \geq N$. Therefore, 
    \[|a_n| = |a_n - a_N + a_N| \leq |a_n - a_N| + |a_N| < 1 + |a_N| \ \forall \ n \geq N\]
    Let $M =\max\{|a_1|, \ldots, |a_{N+1}|, 1 + |a_N|\}$
    Then $|a_n| \leq M \ \forall \ n \in \NN$, and so $\{a_n\}$ is bounded, as desired.
  \end{proof}
\end{lemma}

\begin{theorem}
  If $\{a_n\}$ is Cauchy, then $\{a_n\}$ converges. 

  \begin{proof}
    If $\{a_n\}$ is Cauchy, then it is bounded by the Lemma above. Since it is bounded, by Sequential Compactness, 
    $\exists \ a_{n_k} \to a, a \in \RR$ and $a_{n_k}$ is a monotone convergent subsequence. We 
    WTS that $|a_n - a| < \epsilon$. Let $\epsilon > 0$. Since $\{a_n\}$ is Cauchy, then $\ \exists \ N_1 \in \NN$ such that 
    $\ \forall \ m,n \geq N_1$, then 
    \[|a_n - a_m| < \frac{\epsilon}{2}\]
    Since $\underset{n\to\infty}{\lim} a_{n_k} = a, \ \exists \ N_2 \in \NN$ such that $n_K \geq N_2$
    \[|a_{n_k} - a| < \frac{\epsilon}{2}\]
    Choose $n, k \geq \max\{N_1, N_2\}$, then 
    \[|a_n - a| \leq |a_n - a_{n_k}| + |a_{n_k - a}| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]
  \end{proof}
\end{theorem}

\begin{definition}
  Given a sequence $\{a_n\}$, we can construct the series (infinite sum) by $\sum_{k=1}^\infty a_k$. We define the 
  \vocab{nth partial sum} as $S_n = \sum_{k=1}^n a_k$.
  We say that the the series converges when the sequence of partial sums $\{s_n\}$ converges. 
  \[\lim_{n\to\infty} S_n = s \implies \sum_{k=1}^\infty a_k = s\]
\end{definition}

\begin{theorem}
  Suppose $\sum_{k=1}^\infty a_k$ converges to $a$, and $\sum_{k=1}^\infty b_k$ converges to $b$.  Then 
  \[\sum_{k=1}^\infty (\alpha a_k + \beta b_k) \to \alpha a + \beta b, \alpha, \beta \in \RR\]
  \begin{proof}
    See Chapter 2, just working with sequences on $\{S_n\}$ partial sums.
  \end{proof}
\end{theorem}

\begin{theorem}
  The \vocab{Cauchy Convergence Criterion for Series}. A series $\sum_{n=0}^\infty a_n$ converges 
  if and only if $\ \forall \ \epsilon > 0, \ \exists \ N \in \NN, \text{ s.t. } \ \forall \ n \geq m \geq N, n,m \in \NN$, then 
  \[|a_{m+1} + \cdots + a_n| < \epsilon\]
  \begin{proof}
    Recall that if a sequence converges if and only if it is Cauchy. If the sequences are partial sums then 
    \[S_n - S_m = \sum_{k=0}^n a_k - \sum_{k=0}^m a_k = \sum_{k=m+1}^n a_k\]
    So, since $S_n$ converges, it is Cauchy, and so 
    \[|S_n - S_n| = |\sum_{k=m+1}^n a_k| < \epsilon\]
  \end{proof}
\end{theorem}

\begin{theorem}
  If $\sum_{n = 0}^\infty a_n$ converges, then $\underset{n\to\infty}{\lim}a_n = 0$. Note that the contrapositive of this is 
  if $\underset{n\to\infty}{\lim}a_n \neq 0 \implies \sum_{n=0}^\infty a_n$ diverges is known as the \vocab{Test for Divergence}.
  We will prove this in the standard way (not the contrapositive).

  \begin{proof}
    Note that $a_n = s_n - s_{n-1} \ \forall \ n \geq 1$. Suppose $\sum_{n=0}^\infty a_n$ converges to $a \in \RR$. By definition of partial sums, $s_n \to a$.
    \begin{align*}
      \lim_{n\to\infty} s_n = a && \lim_{n\to\infty} s_{n-1} = a
    \end{align*}
    And so $\underset{n\to\infty}{\lim}a_n = a - a = 0$
  \end{proof}
\end{theorem}

\begin{note}
  Note that the finite geometric sum formula is 
  \[\sum_{k=0}^n r^k = 1 + r + \cdots + r^k = \frac{1-r^{n-1}}{1 - r}\]
  and 
  \[\lim_{n\to\infty} r^n = 0 \text{ if } |r| < 1\]
\end{note}

\begin{proposition}
  For $r \in \RR$ with $|r| < 1$ then 
  \[\sum_{k=0}^\infty r^k = \frac{1}{1-r}\]
  \begin{proof}
    Consider 
    \[\underset{n\to\infty}{\lim}\sum_{k=0}^n r^k = \underset{n\to\infty}{\lim}(\frac{1-r^{n-1}}{1-r}) = \frac{1}{1-r}(1-0) = \frac{1}{1-r}\]
  \end{proof}
\end{proposition}

\begin{lemma}
  \vocab{Lemma for Comparison Test Proof}. $\{a_k\}$ where $a_k \geq 0 \ \forall \ k$, then $\sum_{k=1}^\infty a_k$ converges $\Longleftrightarrow$ partial sums sequence is bounded.
  \begin{proof}
    Since $a_k \geq 0 \ \forall \ k, \sum_{k=1}^\infty a_k$ is nonnegative, and thus $\{s_n\}$ is monotonically increasing. 
    \[\sum_{k=1}^\infty a_k \text{ conv } \Longleftrightarrow \{s_n\} \text{ conv } \Longleftrightarrow \{s_n\} \text{ is bounded}\]
    by definition of partial sums, and then convergent sequences are bounded. In the reverse direction, use 
    Monotone Convergence Theorem.
  \end{proof}
\end{lemma}

\begin{theorem}
  \vocab{Comparison Test}. $\{a_n\}, \{b_n\}$ sequences with $0 \leq a_k \leq b_k \ \forall \ k$.  \begin{itemize}
    \item If $\sum_{k=1}^\infty b_k$ converges then $\sum_{k=1}^\infty a_k$ also converges. 
    \item If $\sum_{k=1}^\infty a_k$ diverges, then $\sum_{k=1}^\infty b_k$ also diverges.
  \end{itemize}
  \begin{proof}
    $\ \forall \ n \sum_{k=1}^\infty a_k \leq \sum_{k=1}^\infty b_k$ since $a_k \leq b_k \ \forall \ k$. 
    \begin{itemize}
      \item If $\sum_{k=1}^\infty b_k$ converges, say to $b$, then 
      \[\sum_{k=1}^n a_k \leq \sum_{k=1}^n b_k \leq \sum_{k=1}^\infty b_k = b\]
      So $\sum_{k=1}^n a_k$ (partial sums) are bounded by $b$. So $\sum_{k=1}^\infty a_k$ converges by 
      previous lemma. 
      \item Similar.
    \end{itemize}
  \end{proof}
\end{theorem}

\begin{theorem}
  \vocab{Integral Test}. Let $\{a_k\}$ be a sequence of nonnegative numbers and suppose $f: [1, \infty) \to \RR$ is continuous and monotonic decreasing, and $f(k) = a_k \ \forall \ k$.
  Then the series $\sum_{k=1}^\infty a_k$ converges if and only if $\{\int_a^n f(x) dx\}_{n=1}^\infty$ is bounded.
  \begin{proof}
    $f$ is continuous and thus on each bounded interval, it is integrable. Since $f$ is monotonically decreasing, 
    then $\forall \ k \in \NN, \ \forall \ x \in [k, k + 1]$, we have 
    \[a_k = f(k) \geq f(x) \geq f(k + 1) = a_{k+1}\]
    Integrate from $k$ to $k+1$, such that 
    \[\int_k^{k + 1} a_k \geq \int_k^{k+1} f(x) dx \geq \int_k^{k+1}a_{k+1}\]
    \[a_k \geq \int_k^{k+1} f(x) dx \geq a_{k+1}\]
    Sum up all $k$ such that 
    \[\sum_{k=1}^n a_k \geq \sum_{k=1}^n \int_k^{k+1} f \geq \sum_{k=2}^{n+1}a_{k+1}\]
    \[\sum_{k=1}^n a_k \geq \int_1^{n+1} f \geq \sum_{k=2}^{n+1}a_{k+1}\]
    Note that $\int_1^n f$ is bounded above and below by partial sums of $\sum_{k=1}^\infty a_k$. Then use Comparison Test 
    and note that $f$ is monotonically decreasing. 
    \[\sum_{k=1}^\infty a_k \text{ conv } \Longleftrightarrow \{\int_1^n f\} \text{ bdd }\]
  \end{proof}
\end{theorem}

\begin{theorem}
  \vocab{Alternating Series Test}. Let $\{a_k\}$ be monotonically decreasing sequence 
  of nonnegative numbers that converges to $0$. Then the series 
  \[\sum_{k=1}^\infty (-1)^k a_k \text{ converges }\]
  \begin{proof}
    Proof omitted.
  \end{proof}
\end{theorem}

\begin{definition}
  $\sum_{k=1}^\infty a_k$ \vocab{absolutely converges} if $\sum_{k=1}^\infty |a_k|$ converges.
\end{definition}

\begin{theorem}
  \vocab{Absolute Convergence Test}. If $\sum_{k=1}^\infty |a_k|$ converges then $\sum_{k=1}^\infty a_k$ also converges.

  \begin{proof}
    Assume $\sum_{k=1}^\infty |a_k|$ converges. We WTS that $\sum_{k=1}^\infty a_k$ converges. 
    Note that 
    \[a_k + |a_k| = \begin{cases}
      2|a_k| \text{ if } a_k \geq 0\\
      0 \text{ else }
    \end{cases}\]
    and further note that 
    \[0 \leq a_k + |a_k| \leq 2|a_k| \ \forall \ k\]
    Since $\sum_{k=1}^\infty |a_k|$ converges, then $\sum_{k=1}^\infty 2|a_k|$ also converges. So by 
    $(*)$, $\sum (a_k + |a_k|) \leq 2 \sum |a_k|$. The latter converges, so by 
    Comparison Test, $\sum (a_k + |a_k|)$ also converges. 
    Combining, 
    \[\sum a_k = \sum(a_k + |a_k| - |a_k|) = \sum(a_k + |a_k|) - \sum |a_k|\]
    and the first term converges by CT and the second term converges by assumption, so by Linearity, $\sum_{k=1}^\infty a_k$ 
    converges as well.
  \end{proof}
\end{theorem}

\begin{lemma}
  \vocab{Lemma for Ratio Test Proof}. For $\sum_{k=1}^\infty a_k$, suppose $\ \exists \ r \in \RR$ with $0 \leq r < 1$, 
  and $\ \exists \ N \in \NN$ such that $|a_{n+1}| \leq r|a_n| \ \forall \ n \geq N$. Then 
  $\sum_{k=1}^\infty a_k$ absolutely converges. 

  \begin{proof}
    Apply the given iteratively, 
    \[|a_{N + K}| \leq r^k|a_N|\]
    Then the partial sums of $\sum |a_n|$
    \[|a_1| + |a_2| + \cdots + |a_{N + K}| \leq |a_1| + |a_2| + \cdots |a_N|(1 + r + r^2 + \cdots + r^k)\]
    by factoring out $|a_N|$. Note that 
    \[\leq |a_1| + \cdots + |a_N| \left( \frac{1 - r^{k+1}}{1-r}\right)\]
    Taking the limit as $k\to\infty$, we get that the partial sums of $\sum |a_n|$ is 
    \[\leq |a_1| + \cdots + |a_n| \left( \frac{1}{1-r}\right)\]
    Note that the above has no dependence on $K$, so set it to $M$. The sequence of partial sums of $\sum |a_k|$ is 
    bounded $\implies \sum_{k=1}^\infty |a_k|$ converges.
  \end{proof}
\end{lemma}

\begin{theorem}
  \vocab{Ratio Test}. For $\sum_{k=1}^\infty a_k$ suppose $\lim_{n\to\infty} \frac{|a_{n+1}|}{|a_n|} = l$. Then \begin{enumerate} \item If $l < 1$, then $\sum^\infty a_k$ converges absolutely.
    \item If $l > 1$, then $\sum^\infty$ diverges.
  \end{enumerate}

  \begin{proof}

    \hfill

    \begin{enumerate}
      \item Consider the case of $l < 1$. Choose $N$ such that $\ \forall \ n\geq N, \frac{|a_{n+1}|}{|a_n|} < l$.
      $|a_{n+1}| < l|a_n|$, and note that $l < 1$ and so by the previous theorem 
      $\sum^n |a_k|$ converges.
      \item The other case is similar.
    \end{enumerate}
  \end{proof}
\end{theorem}

\subsection{Pointwise Convergence of Sequence of Functions}

\begin{definition}
  From now on, let $D \subseteq \RR$. Given $f: D \to \RR$ and a sequence 
  of functions $\{f_n: D \to \RR\}$, we say $\{f_n\}$ \vocab{converges pointwise} to $f$
  \[\ \forall \ x \in D, \lim_{n\to\infty} f_n(x) = f(x)\]
  We write $f_n \pw f$. 
\end{definition}

\begin{example}
  $f_n = x^n$ for $0 \leq x \leq 1, n \in \NN$. 
  \begin{align*}
    f_1(x) = x && f_2(x) = x^2 && f_3(x) = x^3 && \cdots
  \end{align*}
  Note that when $x=1 \implies \underset{n\to\infty}{\lim}f_n(1) = \underset{n\to\infty}{1} = 1$. 
  But for $0 \leq x < 1 \implies \underset{n\to\infty}{f_n(x)} = \underset{n\to\infty}{\lim}x^n = 0$
  Thus, $\{f_n\}$ converges pointwise to $f$ on $[0, 1]$ where 
  \[f(x) = \begin{cases}
    1, x = 1\\
    0, 0 \leq x < 1
  \end{cases}\]
\end{example}

\begin{example}
  Let the sequence of functions be $f_n(x) = e^{-x^2} \ \forall \ n \in \mathbb{N}$. What does this 
  sequence of functions converge to?

  \begin{proof}[Solution]
    When $x=0 \implies \underset{n\to\infty}{\lim}e^{-n(0)^2} = 1$

    For when $x \neq 0 \implies \underset{n\to\infty}{\lim}e^{-nx^2} = 0$ and so
    \[\{f_n(x)\} \overset{\text{p.w.}}{\longrightarrow} f(x) = \begin{cases} 0, x \neq 0, \\ 1, x = 0 \end{cases} \] 
    Note that limits do not preserve properties (cont, diff, integrable) of sequences of functions.
  \end{proof}
\end{example}

\subsection{Uniform Convergence of a Sequence of Functions}

\begin{definition}
  We say $f_n: D \to \mathbb{R}$ \vocab{converges uniformly} to $f: D \to \mathbb{R}$ 
  if
  \[\epsilon > 0 \ \exists \ N \in \mathbb{N} \text{ s.t } \ \forall \ n \geq N \text{ and } \forall \ x \in D \implies |f(x) - f_n(x)| < \epsilon\]
  We write $f_n \overset{u}{\longrightarrow} f$.

\end{definition}

\begin{example}
  From above, $f_n(x) = x^n$ on $[0, 1]$. We found that
  \[f_n \pw f = \begin{cases} 1, x = 1\\ 0, 0 \leq x < 1\end{cases}\]
  Now we will show that $f_n \overset{u}{\not\longrightarrow} f$. 

  \begin{proof}
    By contradiction, assume that $f_n \overset{u}{\longrightarrow} f$ on $[0, 1]$. Let 
    $\epsilon = \frac{1}{2}$, so by def'n of uniform convergence, $\exists \ N \in \NN$ such that 
    $\forall \ n \geq N \text{ and } \ \forall \ x \in [0, 1]$, we have 
    \[|f_n - f| < \frac{1}{2}\]
    so $x \in [0, 1) \implies |f_n - f| = |x^n - f| < \frac{1}{2}$. But take a sequence of points 
    $x \to 1, x_m = 1 - \frac{1}{m}$ then 
    \[|x_m^n - 0| < \frac{1}{2}\]
    \[|1^n - 0| < \frac{1}{2} \implies |1| < \frac{1}{2}\]
    is a contradiction. 
  \end{proof}
\end{example}

\begin{example}
  Suppose $f_n(x) = e^{-nx^2}, D = \mathbb{R}$. We claim 
  \[f_n \overset{u}{\not\longrightarrow}f = \begin{cases}
    0, x \neq 0\\
    1, x = 0
  \end{cases}\]
  \begin{proof}
    By contradiction, assume $f_n \overset{u}{\longrightarrow} f$. Let $\epsilon = \frac{1}{2}$. 
    $\exists \ N \in \mathbb{N}$ such that $\forall \ n \geq N, \ \forall \ x \in \mathbb{R}$, 
    \[|f_n(x) - f(x)| < \frac{1}{2}\]
    \[|e^{-nx^2} -0| < \frac{1}{2}\]
    For $x \neq 0$, take $x_m = \frac{1}{m}$, so the sequence approaches $0$ as $m \to \infty$
    Now plugging in $x_m$ we get 
    \[|e^{-nx_m^2} - 0| < \frac{1}{2} \implies e^{-x_m^2} < \frac{1}{2}\]
    Take the limit as $m \to \infty$
    \[e^{-\frac{n}{m^2}} < \frac{1}{2} \implies e^0 < \frac{1}{2}\]
    which is a contradiction and so $f_n \overset{u}{\not\longrightarrow} f$
  \end{proof}
\end{example}

\begin{example}
  Let $f_n: [-\frac{1}{2}, \frac{1}{2}] \to \mathbb{R}$ where $f_n = x^n$. 
  Prove that $f_n \overset{u}{\longrightarrow}f$ for $f(x) = 0$.

  \begin{proof}[Solution]
    Let $\epsilon > 0$. We WTS that $|x^n - 0| = |x^n| < \epsilon \ \forall \ x \in [-\frac{1}{2}, \frac{1}{2}]$
    
    Note that $|x^n| < (\frac{1}{2})^n$ since $x \in [-\frac{1}{2}, \frac{1}{2}]$ and $|x| \in [0, \frac{1}{2}]$. However, 
    as
    \[n\to\infty, (\frac{1}{2})^n \to 0, \ \exists \ N \in \mathbb{N} \text{ s.t. } \ \forall \ n \geq N, (\frac{1}{2})^n < \epsilon\]
    by definition of convergence. So if $n \geq N$ and $\forall \ x \in [-\frac{1}{2}, \frac{1}{2}]$ then 
    \[|f_n(x) - f(x)| = |x^n - 0| = |x^n| \leq (\frac{1}{2})^n < \epsilon\]
    and so therefore, $f_n(x) \overset{u}{\longrightarrow} 0$ on $[-\frac{1}{2}, \frac{1}{2}]$
    both pointwise and uniformly. 
  \end{proof}
\end{example}

\begin{definition}
  A sequence of functions $\{f_n\}, f_n: D \to \mathbb{R}$ is said to be 
  \vocab{uniformly Cauchy} if 
  \[\forall \ \epsilon > 0, \ \exists \ N \in \mathbb{N} \text{ s.t. } \ \forall \ n, m \geq N, \ \forall \ x \in D \implies |f_m(x) - f_n(x)| < \epsilon\]
\end{definition}

\begin{theorem}
  \vocab{Weierstrass Uniform Convergence Theorem} states that 
  $\{f_n: D \to \mathbb{R}\}$ is uniformly convergent if and only if $\{f_n\}$ is uniformly Cauchy.

  \begin{proof}
    
    \hfill

    $\Longrightarrow$ Assume $\{f_n\}$ is uniformly convergent. We WTS that $\{f_n\}$ is uniformly Cauchy. 
    Let $\epsilon > 0$. Since $f_n \overset{u}{\longrightarrow} f, \ \exists \ N \in \mathbb{N}$ such that $\ \forall \ n \geq N$ and $\forall \ x \in D$, 
    $|f_n(x) - f(x)| < \frac{\epsilon}{2}$. If $m, n \geq N$, then 
    \[|f_n(x) - f_m(x)| = |f_n - f + f - f_m| \leq |f_n - f| + |f_m - f| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\]

    $\Longleftarrow$ Assume $\{f_n\}$ is uniformly Cauchy. Let $x \in D$. Then 
    \[\forall \ \epsilon > 0, \ \exists \ N \in \mathbb{N} \text{ s.t.}  \forall \ m, n \geq N, |f_n(x) - f_m(x)| < \epsilon\]
    Note that $\{f_n(x)\}$ is a sequence of $y$-vlaues for each $x$. Cauchy implies convergent for all 
    sequences of numbers. Define $f: D \to \mathbb{R}$ such that $\underset{n\to\infty}{f_n(x)} = f(x)$ (pointwise?). 
    Since $\{f_n\}$ is uniformly Cauchy, $\exists N_2 \in \mathbb{N}$ such that $\forall k, l \geq N_2, \ \forall \ x \in D$
    \[|f_k(x) - f_l(x)| < \frac{\epsilon}{2}\]
    We WTS that $f_l \overset{u}{\longrightarrow} f$
    \[-\frac{\epsilon}{2} < f_k(x) - f_l(x) < \frac{\epsilon}{2}\]
    \[f_l - \frac{\epsilon}{2} < f_k < \frac{\epsilon}{2} + f_l + \frac{\epsilon}{2}\]
    Take the limit $\underset{n\to\infty}{f_k} = f$
    \[f_l - \frac{\epsilon}{2} \leq f \leq \frac{\epsilon}{2} + f_l\]
    \[|f-f_l| \leq \frac{\epsilon}{2} < \epsilon\]
    Therefore, $f_l \overset{u}{\longrightarrow} f$ as needed.
  \end{proof}
\end{theorem}

\end{document}

